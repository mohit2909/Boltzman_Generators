{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from math import *\n",
    "from random import gauss,seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajdict = np.load('output.npz')\n",
    "import ast\n",
    "#params = ast.literal_eval(str(trajdict['params']))\n",
    "traj_closed_train = trajdict['traj_closed_train_hungarian']\n",
    "traj_open_train = trajdict['traj_open_train_hungarian']\n",
    "traj_closed_test = trajdict['traj_closed_test_hungarian']\n",
    "traj_open_test = trajdict['traj_open_test_hungarian']\n",
    "x = np.vstack([traj_closed_train, traj_open_train])\n",
    "xval = np.vstack([traj_closed_test, traj_open_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_set = np.vstack([traj_closed_train[:80000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNADE\n",
    "class RNADE(nn.Module):\n",
    "    def __init__(self,dimer_atoms,solvent_atoms):\n",
    "        super(RNADE, self).__init__()\n",
    "        self.dimer_atoms = dimer_atoms\n",
    "        self.solvent_atoms = solvent_atoms\n",
    "        self.total_dims = self.dimer_atoms + self.solvent_atoms\n",
    "        self.i2h = nn.Linear(self.total_dims-1, self.total_dims-1)\n",
    "        self.h2o = nn.Linear(self.total_dims-1, self.total_dims-self.dimer_atoms)\n",
    "        self.D = self.total_dims\n",
    "        self.H = 256\n",
    "        self.params = nn.ParameterDict({\n",
    "            \"V\" : nn.Parameter(torch.randn(self.D, self.H)),\n",
    "            \"b\" : nn.Parameter(torch.zeros(self.D)),\n",
    "            \"V2\" : nn.Parameter(torch.randn(self.D, self.H)),\n",
    "            \"b2\" : nn.Parameter(torch.zeros(self.D)),\n",
    "            \"W\" : nn.Parameter(torch.randn(self.H, self.D)),\n",
    "            \"c\" : nn.Parameter(torch.zeros(1, self.H)),\n",
    "        })\n",
    "        nn.init.xavier_normal_(self.params[\"V\"])\n",
    "        nn.init.xavier_normal_(self.params[\"V2\"])\n",
    "        nn.init.xavier_normal_(self.params[\"W\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ai = self.params[\"c\"].expand(x.size(0), -1)   #B x H\n",
    "        print(ai.size())\n",
    "        a1=[]\n",
    "        m1 = []\n",
    "        for d in range(self.D):\n",
    "            h_i = torch.relu(ai) #B x H\n",
    "            alpha1 = torch.sigmoid( h_i.mm(self.params[\"V\"][d:d+1,:].t() ) + self.params[\"b\"][d:d+1] )*2  + pow(10,-1) + 0.5#  BxH *  Hx1  \n",
    "            mean1 = h_i.mm(self.params[\"V2\"][d:d+1,:].t() ) + self.params[\"b2\"][d:d+1]\n",
    "            a1.append(alpha1)\n",
    "            m1.append(mean1)\n",
    "\n",
    "            ai = x[:, d:d+1].mm(self.params[\"W\"][:, d:d+1].t() ) + ai #Bx1 * 1xH =  BxH\n",
    "        \n",
    "        a1 = torch.cat(a1,1)\n",
    "        m1 = torch.cat(m1,1)\n",
    "        final_prob = torch.stack([m1,a1])       \n",
    "        return final_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunct(output,pred,ind):\n",
    "    alpha = output[1, :,4:]\n",
    "    mean = output[0, :, 4:]\n",
    "    loss = torch.exp( -0.5 *  ( (pred[:,4:]- mean)/alpha)**2  )/(alpha*sqrt(2*3.14) ) +pow(10,-10)\n",
    "    print(\"Loss:\")\n",
    "    return -torch.log( loss ).sum(axis= 0)[ind]/alpha.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otherLoss(output,pred):\n",
    "    alpha = output[1, :,4:]\n",
    "    mean = output[0, :, 4:]\n",
    "    loss = torch.exp( -0.5 *  ( (pred[:,4:]- mean)/alpha)**2  )/(alpha*sqrt(2*3.14) ) +pow(10,-10)\n",
    "    print(\"Loss:\")\n",
    "    return -torch.log( loss ).sum(axis= 0).sum()/alpha.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixtureLoss(output,pred):\n",
    "    mean= output[0]\n",
    "    alpha = output[2]\n",
    "    std = output[1]\n",
    "    k=2\n",
    "    ans = None;\n",
    "    for i in range(k):\n",
    "        print(alpha[:,:,i].size())\n",
    "        loss = alpha[ :, :,i]* torch.exp(-0.5 * ( (pred[:,4:] -mean[ :, :,i])/std[ :, :,i])**2 ) / (std[ :, :,i]*sqrt(2*3.14))\n",
    "        if(ans is not None):\n",
    "            ans = ans - torch.log(loss).sum(axis=0).sum()/256\n",
    "        else:\n",
    "            ans = -torch.log(loss).sum(axis=0).sum()/256\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNADE2(nn.Module):\n",
    "    def __init__(self,dimer_atoms,solvent_atoms):\n",
    "        super(RNADE2, self).__init__()\n",
    "        self.dimer_atoms = dimer_atoms\n",
    "        self.solvent_atoms = solvent_atoms\n",
    "        self.D = self.dimer_atoms + self.solvent_atoms\n",
    "        self.H = 128\n",
    "        self.K = 2\n",
    "        self.params = nn.ParameterDict({\n",
    "            \"V\" : nn.Parameter(torch.randn(self.D, self.H)),\n",
    "            \"b\" : nn.Parameter(torch.zeros(self.D)),\n",
    "            \"V2\" : nn.Parameter(torch.randn(self.D, self.H)),\n",
    "            \"b2\" : nn.Parameter(torch.zeros(self.D)),\n",
    "            \"Vmean\" : nn.Parameter(torch.randn(self.D,self.H, self.K)),\n",
    "            \"Valpha\" : nn.Parameter(torch.randn(self.D,self.H, self.K)),\n",
    "            \"Vstd\" : nn.Parameter(torch.randn(self.D,self.H, self.K)),\n",
    "            \"bmean\" : nn.Parameter(torch.zeros(self.D,self.K)),\n",
    "            \"balpha\" : nn.Parameter(torch.zeros(self.D,self.K)),\n",
    "            \"bstd\" : nn.Parameter(torch.zeros(self.D,self.K)),\n",
    "            \"W\" : nn.Parameter(torch.randn(self.H, self.D)),\n",
    "            \"c\" : nn.Parameter(torch.zeros(1, self.H)),\n",
    "        })\n",
    "        nn.init.xavier_normal_(self.params[\"V\"])\n",
    "        nn.init.xavier_normal_(self.params[\"V2\"])\n",
    "        nn.init.xavier_normal_(self.params[\"W\"])\n",
    "        nn.init.xavier_normal_(self.params[\"Vmean\"])\n",
    "        nn.init.xavier_normal_(self.params[\"Valpha\"])\n",
    "        nn.init.xavier_normal_(self.params[\"Vstd\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ai = self.params[\"c\"].expand(x.size(0), -1)   #B x H\n",
    "        a= None\n",
    "        m = None\n",
    "        s = None\n",
    "        for d in range(self.D):\n",
    "            if(d<4):\n",
    "                ai = x[:, d:d+1].mm(self.params[\"W\"][:,d:d+1].t()) + ai\n",
    "                continue\n",
    "            h_i = torch.relu(ai) #B x H\n",
    "            std = torch.sigmoid( ( h_i.mm(self.params[\"Vstd\"][d,:,] ) + self.params[\"bstd\"][d:d+1,:].expand(x.size(0), -1) ) )*2  + pow(10,-1) + 0.5#  BxH *  HxK = BxK  \n",
    "            mean = ( h_i.mm(self.params[\"Vmean\"][d,:,] ) + self.params[\"bmean\"][d:d+1,:].expand(x.size(0), -1) ) #B xH  * HxK  = B x K + BxK\n",
    "            alpha = torch.softmax( (h_i.mm(self.params[\"Valpha\"][d,:,] ) +self.params[\"balpha\"][d:d+1,:].expand(x.size(0), -1) ), dim = 0 )\n",
    "            if(a is not None):\n",
    "                a = torch.cat((a, alpha.unsqueeze(dim = 0)),0)\n",
    "                m = torch.cat((m, mean.unsqueeze(dim = 0)) , 0)\n",
    "                s = torch.cat((s, std.unsqueeze(dim = 0)) , 0)\n",
    "            else:\n",
    "                a = alpha.unsqueeze(dim=0)\n",
    "                m = mean.unsqueeze(dim=0)\n",
    "                s = std.unsqueeze(dim=0)\n",
    "            ai = x[:, d:d+1].mm(self.params[\"W\"][:, d:d+1].t() ) + ai #Bx1 * 1xH =  BxH\n",
    "        \n",
    "        m = m.permute(1,0,2 )\n",
    "        a = a.permute(1,0,2)\n",
    "        s = s.permute(1,0,2)\n",
    "        #print(a.size(),m.size(),s.size())\n",
    "        #final_prob = torch.stack([m,s,a]) \n",
    "        #print(final_prob.size())\n",
    "        return [m,s,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNADE2(4,72).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1139.71337890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1106.256103515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1082.85107421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1064.3212890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1048.92236328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1035.8818359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1026.700439453125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1020.3818359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1013.9923706054688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "1006.089111328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "999.3118286132812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "993.8810424804688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "987.244384765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "978.217041015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "970.4793701171875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "965.0411376953125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "958.3087158203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "950.4777221679688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "945.19970703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "939.9722900390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "934.4844970703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "929.1903686523438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "925.9625244140625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "922.3316650390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "918.5335693359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "916.3165283203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "912.4818115234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "909.9791259765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "908.1566162109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "905.4627685546875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "902.9024658203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "901.88720703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "898.509521484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "898.0995483398438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "896.3677978515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "895.2526245117188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "894.7156982421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "893.238525390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "892.7666625976562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "890.658203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "891.2232055664062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "890.3326416015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "889.24365234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "887.740966796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "888.449951171875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "886.414306640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "886.3486328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "885.0447998046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "884.928466796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "884.362060546875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "883.504638671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "882.2181396484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "881.8575439453125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "881.4405517578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "881.2239990234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "880.3582763671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "880.4837646484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "879.1888427734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "878.717041015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "878.766845703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "878.5866088867188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "878.6571655273438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "877.8875732421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "878.211669921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "877.925537109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "878.3558349609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "877.398681640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "877.67236328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "877.1707153320312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.855712890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "877.4703979492188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.8610229492188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.5655517578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.1632080078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.2651977539062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.3836669921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.2279663085938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "875.1220703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.1533203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "876.1558837890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "875.293212890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "875.4671020507812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "875.0758056640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "875.1966552734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "875.8916015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "874.3782958984375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "874.55810546875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "874.3636474609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.701416015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.816650390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.620361328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.8483276367188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "874.4151611328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.1890869140625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.35107421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.933837890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.8339233398438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.0357666015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "873.5963745117188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.2320556640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.5082397460938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.8873901367188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.5986328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.7252197265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.90673828125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.2836303710938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.4271850585938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.3142700195312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.5355224609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.6425170898438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.0971069335938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.5994873046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.0548706054688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.9373779296875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.1090698242188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.4876098632812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.8770141601562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.9642333984375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.126953125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "872.0994873046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.06640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.2312622070312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.5419921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.4131469726562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.6915283203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.4334716796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.2232055664062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.497314453125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.2217407226562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.3212890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.4959716796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.374755859375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871.638427734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.3636474609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.38330078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.21142578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.94482421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.6710205078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.197509765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.4716796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.8242797851562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "871.92822265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.561767578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.9083862304688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.2588500976562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.59375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.8744506835938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.5556640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.2579345703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.47607421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.8297729492188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.9005126953125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.8587646484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.7100830078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.226318359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.4249877929688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.90478515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.5025024414062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.490478515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.1719970703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.402099609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.9888916015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.343994140625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.7716064453125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.00244140625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.1283569335938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.8093872070312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.3980102539062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.127197265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.4644165039062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.9425048828125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.8961181640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "870.0316162109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.847412109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.9107666015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.807373046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.7413330078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.578857421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.6932373046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.4028930664062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.2590942382812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.8571166992188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.3214111328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.357421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.9883422851562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.177734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.185546875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.3197631835938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.7354736328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.2750854492188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.2193603515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.33837890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.6217041015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.9732666015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.7362670898438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.9229736328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.1106567382812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.4554443359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.2362670898438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.0616455078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.1453857421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.8094482421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.4364013671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.0343627929688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.90673828125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.171875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.046630859375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.49169921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.9027099609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.1541748046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.7237548828125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.237548828125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.87451171875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.291259765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.726318359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.8521118164062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "869.1976318359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.446533203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.8302001953125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.3336181640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.3355712890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.908447265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.709228515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.0989990234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.7020874023438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.9794921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.8375244140625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.1527709960938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.0650634765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.1629638671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.1278686523438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.013427734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.3555297851562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.213134765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.04345703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.8397216796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.3657836914062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.24609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.0843505859375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.1199951171875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.880615234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.9542236328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.9255981445312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.5188598632812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.2189331054688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.837158203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.8043823242188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.616943359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.3692626953125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.7503662109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.5995483398438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.909912109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.7405395507812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.0936279296875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.6414184570312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.1026611328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.771728515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.6531982421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "868.0112915039062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.4189453125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.4754638671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.7474365234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.81103515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.712158203125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.3695068359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.427734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.8404541015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.2306518554688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.22998046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.4710693359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.3473510742188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.5906982421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.392578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.36865234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.3035888671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1874389648438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1506958007812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1419677734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.400390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1756591796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9678955078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.2567138671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.228515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.2549438476562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.4248046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.3320922851562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7391357421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.242431640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.6053466796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.0587768554688\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.8271484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.253173828125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.0806884765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.93115234375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9775390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.888671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.2723388671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.81103515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9027099609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.2675170898438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.156005859375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.0181884765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6259155273438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9754028320312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1609497070312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.839111328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.0062255859375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1824951171875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7523193359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6406860351562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.4376220703125\n",
      "torch.Size([128, 72])\n",
      "torch.Size([128, 72])\n",
      "383.6923522949219\n",
      "Running Loss is 275736.73641967773\n",
      "1\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.027587890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1898803710938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.121337890625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.81591796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.947021484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.207275390625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1083374023438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.1383056640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9420166015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9610595703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "867.0110473632812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6129760742188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.8793334960938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7294921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7891235351562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6810302734375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9127197265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.788818359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7665405273438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5726318359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.60009765625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.31396484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.717529296875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5232543945312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.388671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.516357421875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.3302001953125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5318603515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.8710327148438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.60498046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.67822265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.347412109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5433349609375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.4976806640625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5325317382812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.74267578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7777709960938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.3677978515625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9588623046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6627197265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.2463989257812\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.72021484375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.4498291015625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5543823242188\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.4122314453125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6595458984375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.7157592773438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5797119140625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.347412109375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.3963623046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.2855834960938\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.2757568359375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.095458984375\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.4267578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.522705078125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6258544921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.553466796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.19091796875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.1864013671875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.6339111328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.376220703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.2538452148438\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.2686767578125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.9653930664062\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.1229248046875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.5008544921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.1805419921875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.1804809570312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.3057250976562\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.487060546875\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.267822265625\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.4111328125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.204345703125\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n",
      "866.0896606445312\n",
      "torch.Size([256, 72])\n",
      "torch.Size([256, 72])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = model(data)\n",
    "            loss = MixtureLoss(x_hat, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(loss.item())\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "    torch.save(model.state_dict(), 'RNADEtemp2')\n",
    "    print(\"Running Loss is \" + str(running_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 256, 2])\n",
      "torch.Size([256, 72, 2]) torch.Size([256, 72, 2]) torch.Size([256, 72, 2])\n",
      "tensor([0.4983, 0.5017], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (72) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-cf3f34451086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-c5a4969afc4e>\u001b[0m in \u001b[0;36mlossFunct\u001b[0;34m(output, pred, ind)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3.14\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (72) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for ind in range(72):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = model(data)\n",
    "            print(x_hat[2][0][0])\n",
    "            loss = lossFunct(x_hat, data,ind)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(loss.item())\n",
    "           \n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    torch.save(model.state_dict(), 'RNADEtemp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNADE2:\n\tMissing key(s) in state_dict: \"params.Valpha\", \"params.Vmean\", \"params.Vstd\", \"params.balpha\", \"params.bmean\", \"params.bstd\". \n\tUnexpected key(s) in state_dict: \"i2h.weight\", \"i2h.bias\", \"h2o.weight\", \"h2o.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-393-2f4eb2b11913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RNADEOpen2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RNADE2:\n\tMissing key(s) in state_dict: \"params.Valpha\", \"params.Vmean\", \"params.Vstd\", \"params.balpha\", \"params.bmean\", \"params.bstd\". \n\tUnexpected key(s) in state_dict: \"i2h.weight\", \"i2h.bias\", \"h2o.weight\", \"h2o.bias\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"RNADEOpen2\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([72, 256, 2])\n",
      "torch.Size([256, 72, 2]) torch.Size([256, 72, 2]) torch.Size([256, 72, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (72) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-386-98811f8874f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0motherLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-d87413a21901>\u001b[0m in \u001b[0;36motherLoss\u001b[0;34m(output, pred)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3.14\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (72) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = model(data)\n",
    "            loss = otherLoss(x_hat, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(loss.item())\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "    torch.save(model.state_dict(), 'RNADEClosed2')\n",
    "    print(\"Running Loss is \" + str(running_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
