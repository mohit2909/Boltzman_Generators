{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/mohit.kumargupta/deep_boltzmann')\n",
    "import numpy as np\n",
    "import mdtraj as md\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from math import *\n",
    "from random import gauss,seed\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityEstimator(nn.Module):\n",
    "    def __init__(self,dimer_atoms,output_dim):\n",
    "        super(DensityEstimator, self).__init__()\n",
    "        self.dimer_atoms = dimer_atoms\n",
    "        self.hidden_dim = 256\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.fc1 = nn.Linear(self.dimer_atoms, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, int(self.hidden_dim/2) )\n",
    "        self.fc3 = nn.Linear(int(self.hidden_dim/2), int(self.hidden_dim/4))\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.relu( self.fc1(x) )\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        out = 1160*torch.softmax(out,1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixShuf(nn.Module):\n",
    "    def __init__(self, up):\n",
    "        super(PixShuf,self).__init__()\n",
    "        self.upsample = up\n",
    "    def forward(self,inp):\n",
    "        out = inp.reshape((inp.shape[0],inp.shape[1]//(self.upsample**3), self.upsample,self.upsample, self.upsample, inp.shape[2],inp.shape[3],inp.shape[4]))\n",
    "        out = out.permute(0,1,5,2,6,3,7,4)\n",
    "        out = out.reshape((out.shape[0],out.shape[1],inp.shape[2]*self.upsample,inp.shape[3]*self.upsample,inp.shape[4]*self.upsample))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESNET(nn.Module):\n",
    "    def __init__(self,numberOfLayers= 18, dim = 4):\n",
    "        super(RESNET, self).__init__()\n",
    "        self.conv_input = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.residual = self.make_layer(Residual_Block, numberOfLayers)\n",
    "        self.upscale2x = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=64, out_channels=256*2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            PixShuf(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv_output = nn.Conv3d(in_channels=64, out_channels=1, kernel_size=5, stride=1, padding=2, bias= False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv_input(x))\n",
    "        residual = out\n",
    "        out = self.residual(out)\n",
    "        out = torch.add(out,residual)\n",
    "        #self.relu(F.pixel_shuufle)\n",
    "        #out = self.relu( F.pixel_shuffle( self.UpScaleConv(out), 2) )\n",
    "        out = self.upscale2x(out)\n",
    "        out = self.conv_output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Residual_Block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in1 = nn.InstanceNorm3d(64, affine=True)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in2 = nn.InstanceNorm3d(64, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity_data = x\n",
    "        output = self.in1( self.relu(self.conv1(x)) )\n",
    "        output = self.in2( self.conv2(output) )\n",
    "        output = torch.add(output,identity_data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineModel(nn.Module):\n",
    "    def __init__(self,model1,model2,model3):\n",
    "        super(CombineModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "    \n",
    "    def forward(self,inp):\n",
    "        out = self.model1(inp)\n",
    "        out = torch.reshape(out,(inp.shape[0],1,4,4,4) )\n",
    "        print(out.shape)\n",
    "        out = self.model2(out)\n",
    "        out = self.model3(out)\n",
    "        print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,model1):\n",
    "        super(ConfigurationModel,self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.hidden_dim = 16*16\n",
    "        self.out_dim = 11\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.fc1 = nn.Linear(256*16, 100)\n",
    "        self.fc2 = nn.Linear(100, 1164*3)\n",
    "    \n",
    "    def forward(self,inp):\n",
    "        out = self.model1(inp)\n",
    "        out = out.reshape((inp.shape[0],256*16))\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz =16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes =[]\n",
    "x=0\n",
    "while(x<3.3):\n",
    "    y=0.0\n",
    "    while(y<3.3):\n",
    "        z=0.0\n",
    "        while(z<3.31):\n",
    "            boxes.append([x+ 3.4/(2*sz),y+3.4/(2*sz),z+3.4/(2*sz)])\n",
    "            z+=3.4/sz\n",
    "        y+= 3.4/sz\n",
    "    x+= 3.4/sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = np.array(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = (3.4/sz) **3\n",
    "box_size= 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1= DensityEstimator(42*3,64).to('cuda')\n",
    "m2 = RESNET(9,dim=4).to('cuda')\n",
    "m3 = RESNET(9,dim=8).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comModel = CombineModel(m1,m2,m3).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "configModel = ConfigurationModel(comModel).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.arange(160)\n",
    "validPerm = np.arange(20)+160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adOptimizer = optim.Adam(configModel.parameters(),lr =0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNeighbourList():\n",
    "    global boxes\n",
    "    bx = []\n",
    "    for p,eachBox in enumerate(boxes):\n",
    "        box = []\n",
    "        for i in range(5) :\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    x= (int(p/256) + i-2)%16\n",
    "                    y=  ( int( (p%256)/16 ) +j-2)%16\n",
    "                    z = ( int(p%16) + k-2 ) %16\n",
    "                    while(x<0):\n",
    "                        x+=16\n",
    "                    while(y<0):\n",
    "                        y+=16\n",
    "                    while(z<0):\n",
    "                        z+=16\n",
    "                    box.append(np.array(boxes[x*256 +y*16 +z] ) )\n",
    "        bx.append(np.array(box))\n",
    "    return bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeighbourList = np.array(findNeighbourList())\n",
    "NeighbourList = torch.from_numpy(NeighbourList).type('torch.FloatTensor').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otherDMapCalc(temp):\n",
    "    global NeighbourList\n",
    "    DensityMap = None\n",
    "    box_size =3.4\n",
    "    # FUnction to Look at and NeighbourList Function is implemented above\n",
    "    # temp is used for snapshots\n",
    "    %%time\n",
    "    for i,snapshot in enumerate(temp):\n",
    "        print(i)\n",
    "        snapshot= torch.from_numpy(snapshot).to('cuda')\n",
    "        myBox = (torch.floor((snapshot+box_size)*sz/box_size)%16 ).type('torch.IntTensor')\n",
    "        myBox = myBox[:,0]*256 + myBox[:,1]*16 + myBox[:,2] #Finding Box Number\n",
    "\n",
    "        MyList = []\n",
    "        for box in myBox:\n",
    "            MyList.append(NeighbourList[box].detach().to('cpu').numpy())\n",
    "\n",
    "        MyList = torch.from_numpy(np.array(MyList)).type('torch.FloatTensor')\n",
    "        MyList = MyList.to('cuda')\n",
    "\n",
    "        box_size =3.4\n",
    "        dx= torch.abs( (snapshot.unsqueeze(1).expand(-1,125,-1) -MyList) )\n",
    "        dist = torch.norm( dx - box_size*torch.floor(0.5+dx/box_size),dim=2) #calculating distance using minimum image\n",
    "        prob = torch.exp(-0.5 * torch.mul(dist/0.2,dist/0.2))/((2*3.14*0.04)**1.5 )\n",
    "\n",
    "        MyList = torch.floor( (MyList*sz+ 0.01)/box_size )\n",
    "        MyList = (MyList[:,:,0]*256 + MyList[:,:,1]*16  + MyList[:,:,2]).type('torch.IntTensor')\n",
    "        print(MyList.shape,MyList[0,0])\n",
    "\n",
    "        dMap = torch.ones(4096) - 1.0\n",
    "        break\n",
    "        for j in range(4096):\n",
    "                idx = (MyList==j).nonzero()\n",
    "\n",
    "        '''\n",
    "        newList = []\n",
    "        for j in range(MyList.shape[0]):\n",
    "            for k in range(125):\n",
    "                newList.append(j)\n",
    "        newList = torch.from_numpy(np.array(newList))\n",
    "        print(MyList[1,0],MyList.flatten()[125])\n",
    "        out = torch.stack((newList.type('torch.IntTensor'),MyList.flatten()))\n",
    "        dMap = torch.sparse.FloatTensor(out.type('torch.cuda.LongTensor'),prob.flatten())\n",
    "        dMap = torch.sparse.sum(dMap,0)*vol \n",
    "        '''\n",
    "        '''\n",
    "        break\n",
    "        newList = None\n",
    "        for (j,atom) in enumerate(MyList):\n",
    "            if(newList is None):\n",
    "                newList = torch.stack( (torch.ones(125,dtype = torch.int).new_full((1,125),j).squeeze(0), MyList[j]) ).permute(1,0)\n",
    "            else:\n",
    "                newList= torch.cat( (torch.stack( (torch.ones(1,dtype = torch.int).new_full((1,125),j).squeeze(0) , MyList[j]),0 ).permute(1,0), newList ) )\n",
    "        #newList = torch.from_numpy(np.array(newList)).to('cuda').type('torch.cuda.LongTensor')\n",
    "        print(newList.t().shape)\n",
    "        d = torch.sparse.FloatTensor(newList.t().type('torch.cuda.LongTensor'),prob.flatten())\n",
    "        #print(torch.sparse.sum(d,0)*vol)\n",
    "        break\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>To Look at Lost Function </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DensityMapCalc(traj):\n",
    "    global NeighbourList\n",
    "    DensityMap = None\n",
    "    box_size =3.4\n",
    "    for i,snapshot in enumerate(traj):\n",
    "        print(i)\n",
    "        snapshot= snapshot.to('cuda')\n",
    "        myBox = (torch.floor((snapshot+box_size)*sz/box_size)%16 ).type('torch.IntTensor')\n",
    "        myBox = myBox[:,0]*256 + myBox[:,1]*16 + myBox[:,2]\n",
    "\n",
    "        MyList = []\n",
    "        for box in myBox:\n",
    "            MyList.append(NeighbourList[box].detach().to('cpu').numpy())\n",
    "\n",
    "        MyList = torch.from_numpy(np.array(MyList)).type('torch.FloatTensor')\n",
    "        MyList = MyList.to('cuda')\n",
    "        \n",
    "        dx= torch.abs( (snapshot.unsqueeze(1).expand(-1,125,-1) -MyList) )\n",
    "        dist = torch.norm( dx - box_size*torch.floor(0.5+dx/box_size),dim=2)\n",
    "        prob = torch.exp(-0.5 * torch.mul(dist/0.2,dist/0.2))/((2*3.14*0.04)**1.5 )\n",
    "\n",
    "        MyList = torch.floor( (MyList*sz+ 0.01)/box_size )\n",
    "        MyList = (MyList[:,:,0]*256 + MyList[:,:,1]*16  + MyList[:,:,2]).type('torch.IntTensor')\n",
    "        print(MyList.max(),MyList.shape)\n",
    "        break\n",
    "        newList = []\n",
    "        for j in range(1064):\n",
    "            idx = (MyList==j).nonzero()\n",
    "            \n",
    "        for j in range(MyList.shape[0]):\n",
    "            for k in range(125):\n",
    "                newList.append(j)\n",
    "        newList = torch.from_numpy(np.array(newList))\n",
    "        #print(MyList[1,0],MyList.flatten()[125])\n",
    "        out = torch.stack((newList.type('torch.IntTensor'),MyList.flatten()))\n",
    "        dMap = torch.sparse.FloatTensor(out.type('torch.cuda.LongTensor'),prob.flatten()).to_dense()\n",
    "        dMap = dMap.sum(0)*vol\n",
    "        print(dMap.shape,dMap)\n",
    "        if(DensityMap is None):\n",
    "            DensityMap = dMap.unsqueeze(0)\n",
    "        else:\n",
    "            DensityMap = torch.cat((DensityMap,dMap.unsqueeze(0)))\n",
    "    return DensityMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DensitylossFunction(out,sample):\n",
    "    Density = DensityMapCalc(out.reshape((out.shape[0],1164,3)))\n",
    "    print(sample.shape,Density.shape)\n",
    "    return nn.MSELoss()(Density,sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrajDirectory = \"/home/mohit.kumargupta/confALA4/\"\n",
    "TrajFile = TrajDirectory +  \"traj_comp.xtc\"\n",
    "TopFile = TrajDirectory + \"ala4_amber_atA.gro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtObject = md.load(TrajFile, top = TopFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 25\n",
      "tensor(1159., device='cuda:0')\n",
      "torch.Size([500, 1, 4, 4, 4])\n",
      "torch.Size([500, 1, 16, 16, 16])\n",
      "torch.Size([500, 3492])\n",
      "torch.Size([500, 3492])\n",
      "0\n",
      "torch.Size([4096]) tensor([53.4556, 27.1016,  6.2572,  ...,  0.9862, 10.4174, 32.8487],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "1\n",
      "torch.Size([4096]) tensor([53.4477, 27.1020,  6.2585,  ...,  0.9881, 10.4163, 32.8438],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "2\n",
      "torch.Size([4096]) tensor([53.4429, 27.1019,  6.2620,  ...,  0.9864, 10.4165, 32.8426],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "3\n",
      "torch.Size([4096]) tensor([53.4430, 27.1001,  6.2610,  ...,  0.9863, 10.4166, 32.8439],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "4\n",
      "torch.Size([4096]) tensor([53.4384, 27.1001,  6.2622,  ...,  0.9864, 10.4163, 32.8416],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "5\n",
      "torch.Size([4096]) tensor([53.4391, 27.1015,  6.2625,  ...,  0.9864, 10.4151, 32.8396],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "6\n",
      "torch.Size([4096]) tensor([53.4222, 27.0958,  6.2650,  ...,  0.9862, 10.4130, 32.8288],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "7\n",
      "torch.Size([4096]) tensor([53.4245, 27.0933,  6.2632,  ...,  0.9861, 10.4142, 32.8321],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "8\n",
      "torch.Size([4096]) tensor([53.4233, 27.0960,  6.2650,  ...,  0.9864, 10.4134, 32.8294],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "9\n",
      "torch.Size([4096]) tensor([53.4259, 27.0951,  6.2641,  ...,  0.9862, 10.4136, 32.8309],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "10\n",
      "torch.Size([4096]) tensor([53.4279, 27.0951,  6.2634,  ...,  0.9861, 10.4135, 32.8315],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "11\n",
      "torch.Size([4096]) tensor([53.4391, 27.0941,  6.2578,  ...,  0.9861, 10.4159, 32.8419],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "12\n",
      "torch.Size([4096]) tensor([53.4371, 27.0954,  6.2593,  ...,  0.9861, 10.4154, 32.8398],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "13\n",
      "torch.Size([4096]) tensor([53.4369, 27.0966,  6.2601,  ...,  0.9861, 10.4149, 32.8382],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "14\n",
      "torch.Size([4096]) tensor([53.4398, 27.0950,  6.2572,  ...,  0.9848, 10.4186, 32.8434],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "15\n",
      "torch.Size([4096]) tensor([53.4249, 27.0936,  6.2632,  ...,  0.9861, 10.4156, 32.8313],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "16\n",
      "torch.Size([4096]) tensor([53.4233, 27.0943,  6.2645,  ...,  0.9862, 10.4152, 32.8290],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "17\n",
      "torch.Size([4096]) tensor([53.4300, 27.0935,  6.2596,  ...,  0.9866, 10.4165, 32.8341],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "18\n",
      "torch.Size([4096]) tensor([53.4245, 27.0940,  6.2643,  ...,  0.9861, 10.4147, 32.8287],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "19\n",
      "torch.Size([4096]) tensor([53.4259, 27.0909,  6.2582,  ...,  0.9883, 10.4150, 32.8313],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "20\n",
      "torch.Size([4096]) tensor([53.4195, 27.0903,  6.2642,  ...,  0.9859, 10.4139, 32.8264],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "21\n",
      "torch.Size([4096]) tensor([53.4317, 27.0906,  6.2610,  ...,  0.9858, 10.4154, 32.8345],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "22\n",
      "torch.Size([4096]) tensor([53.4142, 27.0872,  6.2658,  ...,  0.9839, 10.4123, 32.8218],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "23\n",
      "torch.Size([4096]) tensor([53.4201, 27.0885,  6.2652,  ...,  0.9841, 10.4127, 32.8244],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "24\n",
      "torch.Size([4096]) tensor([53.4219, 27.0864,  6.2612,  ...,  0.9858, 10.4148, 32.8299],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "25\n",
      "torch.Size([4096]) tensor([53.4073, 27.0874,  6.2657,  ...,  0.9860, 10.4127, 32.8207],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "26\n",
      "torch.Size([4096]) tensor([53.4244, 27.0889,  6.2612,  ...,  0.9860, 10.4150, 32.8318],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "27\n",
      "torch.Size([4096]) tensor([53.4125, 27.0833,  6.2602,  ...,  0.9877, 10.4133, 32.8245],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "28\n",
      "torch.Size([4096]) tensor([53.4134, 27.0811,  6.2599,  ...,  0.9847, 10.4115, 32.8230],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "29\n",
      "torch.Size([4096]) tensor([53.4241, 27.0808,  6.2522,  ...,  0.9885, 10.4132, 32.8319],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "30\n",
      "torch.Size([4096]) tensor([53.4268, 27.0856,  6.2577,  ...,  0.9858, 10.4134, 32.8326],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "31\n",
      "torch.Size([4096]) tensor([53.4383, 27.0884,  6.2575,  ...,  0.9849, 10.4146, 32.8394],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "32\n",
      "torch.Size([4096]) tensor([53.4326, 27.0847,  6.2549,  ...,  0.9865, 10.4142, 32.8372],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "33\n",
      "torch.Size([4096]) tensor([53.4190, 27.0832,  6.2605,  ...,  0.9848, 10.4126, 32.8288],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "34\n",
      "torch.Size([4096]) tensor([53.4049, 27.0798,  6.2634,  ...,  0.9837, 10.4103, 32.8190],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "35\n",
      "torch.Size([4096]) tensor([53.3985, 27.0762,  6.2640,  ...,  0.9837, 10.4101, 32.8150],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "36\n",
      "torch.Size([4096]) tensor([53.4157, 27.0813,  6.2616,  ...,  0.9848, 10.4128, 32.8256],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "37\n",
      "torch.Size([4096]) tensor([53.4044, 27.0824,  6.2658,  ...,  0.9839, 10.4105, 32.8169],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "38\n",
      "torch.Size([4096]) tensor([53.4041, 27.0801,  6.2617,  ...,  0.9863, 10.4098, 32.8158],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "39\n",
      "torch.Size([4096]) tensor([53.4218, 27.0822,  6.2596,  ...,  0.9837, 10.4140, 32.8314],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "40\n",
      "torch.Size([4096]) tensor([53.4181, 27.0864,  6.2634,  ...,  0.9850, 10.4130, 32.8281],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "41\n",
      "torch.Size([4096]) tensor([53.4166, 27.0819,  6.2577,  ...,  0.9867, 10.4124, 32.8272],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "42\n",
      "torch.Size([4096]) tensor([53.4132, 27.0820,  6.2603,  ...,  0.9860, 10.4124, 32.8276],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "43\n",
      "torch.Size([4096]) tensor([53.4076, 27.0832,  6.2598,  ...,  0.9887, 10.4118, 32.8236],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "44\n",
      "torch.Size([4096]) tensor([53.4110, 27.0816,  6.2577,  ...,  0.9885, 10.4126, 32.8265],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "45\n",
      "torch.Size([4096]) tensor([53.4152, 27.0830,  6.2592,  ...,  0.9874, 10.4126, 32.8283],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "46\n",
      "torch.Size([4096]) tensor([53.4236, 27.0876,  6.2609,  ...,  0.9867, 10.4131, 32.8320],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "47\n",
      "torch.Size([4096]) tensor([53.4278, 27.0846,  6.2577,  ...,  0.9858, 10.4136, 32.8345],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "48\n",
      "torch.Size([4096]) tensor([53.4233, 27.0841,  6.2574,  ...,  0.9875, 10.4161, 32.8344],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "49\n",
      "torch.Size([4096]) tensor([53.4229, 27.0927,  6.2603,  ...,  0.9896, 10.4136, 32.8303],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "50\n",
      "torch.Size([4096]) tensor([53.4132, 27.0931,  6.2661,  ...,  0.9863, 10.4135, 32.8250],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "51\n",
      "torch.Size([4096]) tensor([53.3970, 27.0887,  6.2707,  ...,  0.9856, 10.4128, 32.8170],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "52\n",
      "torch.Size([4096]) tensor([53.4103, 27.0892,  6.2646,  ...,  0.9871, 10.4141, 32.8255],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "53\n",
      "torch.Size([4096]) tensor([53.4124, 27.0875,  6.2625,  ...,  0.9860, 10.4141, 32.8256],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "54\n",
      "torch.Size([4096]) tensor([53.4120, 27.0817,  6.2543,  ...,  0.9889, 10.4133, 32.8246],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "55\n",
      "torch.Size([4096]) tensor([53.4075, 27.0818,  6.2599,  ...,  0.9869, 10.4146, 32.8228],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "56\n",
      "torch.Size([4096]) tensor([53.3973, 27.0791,  6.2632,  ...,  0.9849, 10.4122, 32.8158],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "57\n",
      "torch.Size([4096]) tensor([53.4046, 27.0810,  6.2613,  ...,  0.9850, 10.4146, 32.8231],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "58\n",
      "torch.Size([4096]) tensor([53.4051, 27.0866,  6.2646,  ...,  0.9863, 10.4142, 32.8209],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "59\n",
      "torch.Size([4096]) tensor([53.4008, 27.0850,  6.2649,  ...,  0.9863, 10.4135, 32.8178],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.4025, 27.0824,  6.2609,  ...,  0.9879, 10.4151, 32.8229],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "61\n",
      "torch.Size([4096]) tensor([53.3809, 27.0791,  6.2661,  ...,  0.9881, 10.4124, 32.8095],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "62\n",
      "torch.Size([4096]) tensor([53.3666, 27.0783,  6.2732,  ...,  0.9846, 10.4104, 32.8001],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "63\n",
      "torch.Size([4096]) tensor([53.3722, 27.0769,  6.2695,  ...,  0.9864, 10.4110, 32.8038],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "64\n",
      "torch.Size([4096]) tensor([53.3749, 27.0766,  6.2686,  ...,  0.9864, 10.4118, 32.8060],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "65\n",
      "torch.Size([4096]) tensor([53.3729, 27.0818,  6.2741,  ...,  0.9856, 10.4109, 32.8027],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "66\n",
      "torch.Size([4096]) tensor([53.3690, 27.0774,  6.2710,  ...,  0.9864, 10.4112, 32.8030],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "67\n",
      "torch.Size([4096]) tensor([53.3632, 27.0757,  6.2704,  ...,  0.9882, 10.4110, 32.8010],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "68\n",
      "torch.Size([4096]) tensor([53.3530, 27.0795,  6.2778,  ...,  0.9847, 10.4096, 32.7945],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "69\n",
      "torch.Size([4096]) tensor([53.3526, 27.0755,  6.2722,  ...,  0.9885, 10.4117, 32.7967],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "70\n",
      "torch.Size([4096]) tensor([53.3438, 27.0733,  6.2773,  ...,  0.9847, 10.4080, 32.7899],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "71\n",
      "torch.Size([4096]) tensor([53.3583, 27.0789,  6.2727,  ...,  0.9884, 10.4106, 32.7961],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "72\n",
      "torch.Size([4096]) tensor([53.3684, 27.0805,  6.2678,  ...,  0.9900, 10.4114, 32.8055],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "73\n",
      "torch.Size([4096]) tensor([53.3491, 27.0757,  6.2750,  ...,  0.9863, 10.4097, 32.7935],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "74\n",
      "torch.Size([4096]) tensor([53.3542, 27.0788,  6.2747,  ...,  0.9864, 10.4114, 32.7981],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "75\n",
      "torch.Size([4096]) tensor([53.3602, 27.0787,  6.2697,  ...,  0.9900, 10.4145, 32.8027],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "76\n",
      "torch.Size([4096]) tensor([53.3652, 27.0754,  6.2680,  ...,  0.9880, 10.4118, 32.8045],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "77\n",
      "torch.Size([4096]) tensor([53.3686, 27.0762,  6.2663,  ...,  0.9898, 10.4120, 32.8065],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "78\n",
      "torch.Size([4096]) tensor([53.3695, 27.0783,  6.2678,  ...,  0.9886, 10.4110, 32.8042],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "79\n",
      "torch.Size([4096]) tensor([53.3757, 27.0749,  6.2657,  ...,  0.9870, 10.4113, 32.8091],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "80\n",
      "torch.Size([4096]) tensor([53.3569, 27.0727,  6.2698,  ...,  0.9871, 10.4091, 32.7970],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "81\n",
      "torch.Size([4096]) tensor([53.3628, 27.0751,  6.2726,  ...,  0.9847, 10.4097, 32.7988],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "82\n",
      "torch.Size([4096]) tensor([53.3630, 27.0706,  6.2685,  ...,  0.9865, 10.4097, 32.8005],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "83\n",
      "torch.Size([4096]) tensor([53.3663, 27.0724,  6.2667,  ...,  0.9872, 10.4092, 32.8008],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "84\n",
      "torch.Size([4096]) tensor([53.3656, 27.0720,  6.2676,  ...,  0.9853, 10.4088, 32.8008],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "85\n",
      "torch.Size([4096]) tensor([53.3607, 27.0721,  6.2686,  ...,  0.9872, 10.4093, 32.7988],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "86\n",
      "torch.Size([4096]) tensor([53.3548, 27.0704,  6.2666,  ...,  0.9905, 10.4089, 32.7958],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "87\n",
      "torch.Size([4096]) tensor([53.3407, 27.0658,  6.2730,  ...,  0.9863, 10.4070, 32.7884],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "88\n",
      "torch.Size([4096]) tensor([53.3444, 27.0652,  6.2673,  ...,  0.9908, 10.4069, 32.7897],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "89\n",
      "torch.Size([4096]) tensor([53.3480, 27.0646,  6.2692,  ...,  0.9879, 10.4078, 32.7915],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "90\n",
      "torch.Size([4096]) tensor([53.3491, 27.0652,  6.2652,  ...,  0.9904, 10.4082, 32.7935],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "91\n",
      "torch.Size([4096]) tensor([53.3544, 27.0666,  6.2626,  ...,  0.9923, 10.4099, 32.7989],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "92\n",
      "torch.Size([4096]) tensor([53.3429, 27.0686,  6.2679,  ...,  0.9924, 10.4076, 32.7896],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "93\n",
      "torch.Size([4096]) tensor([53.3438, 27.0682,  6.2677,  ...,  0.9924, 10.4083, 32.7915],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "94\n",
      "torch.Size([4096]) tensor([53.3392, 27.0675,  6.2685,  ...,  0.9925, 10.4075, 32.7881],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "95\n",
      "torch.Size([4096]) tensor([53.3376, 27.0658,  6.2679,  ...,  0.9924, 10.4063, 32.7861],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "96\n",
      "torch.Size([4096]) tensor([53.3456, 27.0638,  6.2638,  ...,  0.9923, 10.4079, 32.7927],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "97\n",
      "torch.Size([4096]) tensor([53.3443, 27.0666,  6.2675,  ...,  0.9907, 10.4066, 32.7885],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "98\n",
      "torch.Size([4096]) tensor([53.3472, 27.0669,  6.2681,  ...,  0.9888, 10.4078, 32.7915],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "99\n",
      "torch.Size([4096]) tensor([53.3616, 27.0673,  6.2618,  ...,  0.9906, 10.4097, 32.8020],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "100\n",
      "torch.Size([4096]) tensor([53.3531, 27.0686,  6.2651,  ...,  0.9907, 10.4087, 32.7963],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "101\n",
      "torch.Size([4096]) tensor([53.3603, 27.0711,  6.2659,  ...,  0.9888, 10.4091, 32.7994],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "102\n",
      "torch.Size([4096]) tensor([53.3634, 27.0711,  6.2631,  ...,  0.9906, 10.4105, 32.8027],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "103\n",
      "torch.Size([4096]) tensor([53.3640, 27.0714,  6.2629,  ...,  0.9907, 10.4104, 32.8022],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "104\n",
      "torch.Size([4096]) tensor([53.3772, 27.0764,  6.2653,  ...,  0.9879, 10.4110, 32.8071],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "105\n",
      "torch.Size([4096]) tensor([53.3701, 27.0737,  6.2626,  ...,  0.9906, 10.4108, 32.8040],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "106\n",
      "torch.Size([4096]) tensor([53.3692, 27.0731,  6.2637,  ...,  0.9888, 10.4109, 32.8037],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "107\n",
      "torch.Size([4096]) tensor([53.3666, 27.0727,  6.2605,  ...,  0.9925, 10.4103, 32.8023],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "108\n",
      "torch.Size([4096]) tensor([53.3571, 27.0681,  6.2631,  ...,  0.9906, 10.4088, 32.7969],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "109\n",
      "torch.Size([4096]) tensor([53.3639, 27.0699,  6.2651,  ...,  0.9881, 10.4096, 32.8004],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "110\n",
      "torch.Size([4096]) tensor([53.3761, 27.0741,  6.2619,  ...,  0.9888, 10.4115, 32.8070],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "111\n",
      "torch.Size([4096]) tensor([53.3816, 27.0759,  6.2622,  ...,  0.9897, 10.4113, 32.8086],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "112\n",
      "torch.Size([4096]) tensor([53.3842, 27.0731,  6.2609,  ...,  0.9870, 10.4122, 32.8110],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "113\n",
      "torch.Size([4096]) tensor([53.3757, 27.0714,  6.2620,  ...,  0.9871, 10.4116, 32.8062],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "114\n",
      "torch.Size([4096]) tensor([53.3650, 27.0712,  6.2642,  ...,  0.9890, 10.4096, 32.7980],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "115\n",
      "torch.Size([4096]) tensor([53.3676, 27.0705,  6.2631,  ...,  0.9889, 10.4103, 32.8008],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "116\n",
      "torch.Size([4096]) tensor([53.3694, 27.0686,  6.2613,  ...,  0.9890, 10.4121, 32.8047],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "117\n",
      "torch.Size([4096]) tensor([53.3666, 27.0683,  6.2614,  ...,  0.9891, 10.4116, 32.8039],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "118\n",
      "torch.Size([4096]) tensor([53.3652, 27.0700,  6.2608,  ...,  0.9909, 10.4127, 32.8052],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "119\n",
      "torch.Size([4096]) tensor([53.3601, 27.0658,  6.2599,  ...,  0.9909, 10.4123, 32.8038],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.3570, 27.0658,  6.2607,  ...,  0.9909, 10.4127, 32.8035],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "121\n",
      "torch.Size([4096]) tensor([53.3565, 27.0656,  6.2636,  ...,  0.9873, 10.4124, 32.8019],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "122\n",
      "torch.Size([4096]) tensor([53.3531, 27.0649,  6.2632,  ...,  0.9892, 10.4117, 32.7985],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "123\n",
      "torch.Size([4096]) tensor([53.3617, 27.0633,  6.2595,  ...,  0.9891, 10.4130, 32.8048],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "124\n",
      "torch.Size([4096]) tensor([53.3561, 27.0599,  6.2579,  ...,  0.9908, 10.4121, 32.8021],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "125\n",
      "torch.Size([4096]) tensor([53.3564, 27.0578,  6.2566,  ...,  0.9906, 10.4117, 32.8027],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "126\n",
      "torch.Size([4096]) tensor([53.3512, 27.0567,  6.2602,  ...,  0.9889, 10.4108, 32.7982],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "127\n",
      "torch.Size([4096]) tensor([53.3342, 27.0570,  6.2628,  ...,  0.9909, 10.4093, 32.7894],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "128\n",
      "torch.Size([4096]) tensor([53.3441, 27.0577,  6.2598,  ...,  0.9925, 10.4106, 32.7972],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "129\n",
      "torch.Size([4096]) tensor([53.3459, 27.0572,  6.2596,  ...,  0.9924, 10.4100, 32.7954],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "130\n",
      "torch.Size([4096]) tensor([53.3508, 27.0611,  6.2624,  ...,  0.9891, 10.4102, 32.7966],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "131\n",
      "torch.Size([4096]) tensor([53.3475, 27.0629,  6.2621,  ...,  0.9910, 10.4107, 32.7957],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "132\n",
      "torch.Size([4096]) tensor([53.3304, 27.0573,  6.2649,  ...,  0.9909, 10.4094, 32.7862],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "133\n",
      "torch.Size([4096]) tensor([53.3506, 27.0601,  6.2579,  ...,  0.9926, 10.4125, 32.8002],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "134\n",
      "torch.Size([4096]) tensor([53.3598, 27.0629,  6.2583,  ...,  0.9908, 10.4120, 32.8025],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "135\n",
      "torch.Size([4096]) tensor([53.3572, 27.0597,  6.2600,  ...,  0.9892, 10.4110, 32.8000],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "136\n",
      "torch.Size([4096]) tensor([53.3839, 27.0652,  6.2527,  ...,  0.9910, 10.4152, 32.8192],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "137\n",
      "torch.Size([4096]) tensor([53.3844, 27.0697,  6.2541,  ...,  0.9912, 10.4162, 32.8211],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "138\n",
      "torch.Size([4096]) tensor([53.3727, 27.0685,  6.2553,  ...,  0.9927, 10.4153, 32.8143],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "139\n",
      "torch.Size([4096]) tensor([53.3767, 27.0688,  6.2556,  ...,  0.9918, 10.4161, 32.8181],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "140\n",
      "torch.Size([4096]) tensor([53.3683, 27.0703,  6.2606,  ...,  0.9917, 10.4141, 32.8115],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "141\n",
      "torch.Size([4096]) tensor([53.3669, 27.0672,  6.2612,  ...,  0.9899, 10.4132, 32.8097],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "142\n",
      "torch.Size([4096]) tensor([53.3588, 27.0673,  6.2640,  ...,  0.9900, 10.4121, 32.8035],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "143\n",
      "torch.Size([4096]) tensor([53.3559, 27.0679,  6.2673,  ...,  0.9884, 10.4118, 32.8008],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "144\n",
      "torch.Size([4096]) tensor([53.3414, 27.0635,  6.2681,  ...,  0.9885, 10.4100, 32.7915],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "145\n",
      "torch.Size([4096]) tensor([53.3359, 27.0638,  6.2708,  ...,  0.9884, 10.4088, 32.7870],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "146\n",
      "torch.Size([4096]) tensor([53.3417, 27.0659,  6.2698,  ...,  0.9885, 10.4089, 32.7886],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "147\n",
      "torch.Size([4096]) tensor([53.3321, 27.0599,  6.2682,  ...,  0.9885, 10.4086, 32.7844],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "148\n",
      "torch.Size([4096]) tensor([53.3398, 27.0576,  6.2627,  ...,  0.9893, 10.4104, 32.7910],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "149\n",
      "torch.Size([4096]) tensor([53.3319, 27.0598,  6.2679,  ...,  0.9886, 10.4095, 32.7877],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "150\n",
      "torch.Size([4096]) tensor([53.3312, 27.0572,  6.2686,  ...,  0.9884, 10.4096, 32.7887],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "151\n",
      "torch.Size([4096]) tensor([53.3461, 27.0598,  6.2616,  ...,  0.9918, 10.4132, 32.8014],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "152\n",
      "torch.Size([4096]) tensor([53.3338, 27.0591,  6.2672,  ...,  0.9901, 10.4101, 32.7927],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "153\n",
      "torch.Size([4096]) tensor([53.3323, 27.0568,  6.2680,  ...,  0.9883, 10.4085, 32.7879],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "154\n",
      "torch.Size([4096]) tensor([53.3378, 27.0587,  6.2677,  ...,  0.9882, 10.4091, 32.7899],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "155\n",
      "torch.Size([4096]) tensor([53.3400, 27.0592,  6.2671,  ...,  0.9883, 10.4106, 32.7914],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "156\n",
      "torch.Size([4096]) tensor([53.3413, 27.0630,  6.2687,  ...,  0.9884, 10.4113, 32.7935],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "157\n",
      "torch.Size([4096]) tensor([53.3511, 27.0631,  6.2658,  ...,  0.9883, 10.4123, 32.7999],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "158\n",
      "torch.Size([4096]) tensor([53.3573, 27.0632,  6.2644,  ...,  0.9882, 10.4114, 32.7995],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "159\n",
      "torch.Size([4096]) tensor([53.3677, 27.0625,  6.2604,  ...,  0.9881, 10.4144, 32.8070],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "160\n",
      "torch.Size([4096]) tensor([53.3625, 27.0613,  6.2633,  ...,  0.9864, 10.4123, 32.8016],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "161\n",
      "torch.Size([4096]) tensor([53.3542, 27.0595,  6.2615,  ...,  0.9890, 10.4120, 32.7989],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "162\n",
      "torch.Size([4096]) tensor([53.3461, 27.0552,  6.2624,  ...,  0.9873, 10.4108, 32.7971],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "163\n",
      "torch.Size([4096]) tensor([53.3412, 27.0565,  6.2627,  ...,  0.9892, 10.4105, 32.7941],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "164\n",
      "torch.Size([4096]) tensor([53.3473, 27.0548,  6.2591,  ...,  0.9892, 10.4129, 32.8005],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "165\n",
      "torch.Size([4096]) tensor([53.3443, 27.0554,  6.2616,  ...,  0.9874, 10.4132, 32.7990],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "166\n",
      "torch.Size([4096]) tensor([53.3446, 27.0609,  6.2662,  ...,  0.9866, 10.4124, 32.7972],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "167\n",
      "torch.Size([4096]) tensor([53.3627, 27.0634,  6.2606,  ...,  0.9883, 10.4137, 32.8070],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "168\n",
      "torch.Size([4096]) tensor([53.3673, 27.0612,  6.2542,  ...,  0.9902, 10.4147, 32.8109],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "169\n",
      "torch.Size([4096]) tensor([53.3775, 27.0629,  6.2567,  ...,  0.9864, 10.4148, 32.8141],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "170\n",
      "torch.Size([4096]) tensor([53.3739, 27.0584,  6.2517,  ...,  0.9889, 10.4149, 32.8115],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "171\n",
      "torch.Size([4096]) tensor([53.3648, 27.0574,  6.2527,  ...,  0.9891, 10.4139, 32.8056],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "172\n",
      "torch.Size([4096]) tensor([53.3724, 27.0592,  6.2521,  ...,  0.9878, 10.4142, 32.8102],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "173\n",
      "torch.Size([4096]) tensor([53.3666, 27.0542,  6.2499,  ...,  0.9890, 10.4146, 32.8093],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "174\n",
      "torch.Size([4096]) tensor([53.3711, 27.0579,  6.2505,  ...,  0.9890, 10.4148, 32.8113],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "175\n",
      "torch.Size([4096]) tensor([53.3828, 27.0587,  6.2479,  ...,  0.9870, 10.4159, 32.8186],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "176\n",
      "torch.Size([4096]) tensor([53.3743, 27.0570,  6.2521,  ...,  0.9850, 10.4106, 32.8083],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "177\n",
      "torch.Size([4096]) tensor([53.3930, 27.0611,  6.2525,  ...,  0.9840, 10.4136, 32.8212],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "178\n",
      "torch.Size([4096]) tensor([53.3910, 27.0621,  6.2538,  ...,  0.9840, 10.4129, 32.8196],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "179\n",
      "torch.Size([4096]) tensor([53.3932, 27.0601,  6.2497,  ...,  0.9849, 10.4126, 32.8201],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.3928, 27.0596,  6.2497,  ...,  0.9857, 10.4135, 32.8227],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "181\n",
      "torch.Size([4096]) tensor([53.3908, 27.0575,  6.2467,  ...,  0.9865, 10.4143, 32.8193],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "182\n",
      "torch.Size([4096]) tensor([53.3949, 27.0597,  6.2473,  ...,  0.9865, 10.4119, 32.8190],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "183\n",
      "torch.Size([4096]) tensor([53.3948, 27.0617,  6.2485,  ...,  0.9865, 10.4119, 32.8191],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "184\n",
      "torch.Size([4096]) tensor([53.3829, 27.0631,  6.2535,  ...,  0.9850, 10.4075, 32.8091],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "185\n",
      "torch.Size([4096]) tensor([53.3825, 27.0645,  6.2565,  ...,  0.9842, 10.4076, 32.8097],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "186\n",
      "torch.Size([4096]) tensor([53.3945, 27.0687,  6.2565,  ...,  0.9841, 10.4092, 32.8169],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "187\n",
      "torch.Size([4096]) tensor([53.3819, 27.0664,  6.2596,  ...,  0.9841, 10.4072, 32.8087],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "188\n",
      "torch.Size([4096]) tensor([53.3744, 27.0692,  6.2621,  ...,  0.9861, 10.4058, 32.8033],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "189\n",
      "torch.Size([4096]) tensor([53.3690, 27.0664,  6.2641,  ...,  0.9841, 10.4044, 32.7985],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "190\n",
      "torch.Size([4096]) tensor([53.3605, 27.0663,  6.2683,  ...,  0.9841, 10.4021, 32.7900],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "191\n",
      "torch.Size([4096]) tensor([53.3576, 27.0639,  6.2680,  ...,  0.9842, 10.4027, 32.7909],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "192\n",
      "torch.Size([4096]) tensor([53.3744, 27.0646,  6.2633,  ...,  0.9843, 10.4063, 32.8037],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "193\n",
      "torch.Size([4096]) tensor([53.3670, 27.0646,  6.2664,  ...,  0.9843, 10.4059, 32.7991],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "194\n",
      "torch.Size([4096]) tensor([53.3728, 27.0637,  6.2641,  ...,  0.9843, 10.4076, 32.8054],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "195\n",
      "torch.Size([4096]) tensor([53.3771, 27.0640,  6.2614,  ...,  0.9844, 10.4085, 32.8088],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "196\n",
      "torch.Size([4096]) tensor([53.3634, 27.0618,  6.2650,  ...,  0.9843, 10.4087, 32.8005],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "197\n",
      "torch.Size([4096]) tensor([53.3767, 27.0611,  6.2558,  ...,  0.9869, 10.4097, 32.8114],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "198\n",
      "torch.Size([4096]) tensor([53.3776, 27.0612,  6.2555,  ...,  0.9854, 10.4124, 32.8124],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "199\n",
      "torch.Size([4096]) tensor([53.3770, 27.0613,  6.2587,  ...,  0.9844, 10.4110, 32.8105],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "200\n",
      "torch.Size([4096]) tensor([53.3826, 27.0623,  6.2577,  ...,  0.9844, 10.4098, 32.8126],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "201\n",
      "torch.Size([4096]) tensor([53.3798, 27.0624,  6.2585,  ...,  0.9844, 10.4093, 32.8106],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "202\n",
      "torch.Size([4096]) tensor([53.3771, 27.0626,  6.2597,  ...,  0.9843, 10.4085, 32.8086],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "203\n",
      "torch.Size([4096]) tensor([53.3817, 27.0631,  6.2563,  ...,  0.9862, 10.4095, 32.8126],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "204\n",
      "torch.Size([4096]) tensor([53.3719, 27.0634,  6.2598,  ...,  0.9863, 10.4078, 32.8056],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "205\n",
      "torch.Size([4096]) tensor([53.3655, 27.0605,  6.2598,  ...,  0.9863, 10.4076, 32.8032],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "206\n",
      "torch.Size([4096]) tensor([53.3700, 27.0601,  6.2586,  ...,  0.9863, 10.4104, 32.8075],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "207\n",
      "torch.Size([4096]) tensor([53.3675, 27.0585,  6.2610,  ...,  0.9844, 10.4100, 32.8040],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "208\n",
      "torch.Size([4096]) tensor([53.3694, 27.0589,  6.2579,  ...,  0.9868, 10.4105, 32.8053],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "209\n",
      "torch.Size([4096]) tensor([53.3658, 27.0579,  6.2595,  ...,  0.9868, 10.4097, 32.8019],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "210\n",
      "torch.Size([4096]) tensor([53.3746, 27.0617,  6.2580,  ...,  0.9870, 10.4131, 32.8064],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "211\n",
      "torch.Size([4096]) tensor([53.3829, 27.0622,  6.2559,  ...,  0.9869, 10.4147, 32.8132],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "212\n",
      "torch.Size([4096]) tensor([53.3726, 27.0607,  6.2592,  ...,  0.9869, 10.4124, 32.8044],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "213\n",
      "torch.Size([4096]) tensor([53.3830, 27.0651,  6.2590,  ...,  0.9869, 10.4127, 32.8084],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "214\n",
      "torch.Size([4096]) tensor([53.3762, 27.0641,  6.2607,  ...,  0.9869, 10.4115, 32.8045],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "215\n",
      "torch.Size([4096]) tensor([53.3704, 27.0670,  6.2660,  ...,  0.9852, 10.4102, 32.7988],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "216\n",
      "torch.Size([4096]) tensor([53.3816, 27.0676,  6.2622,  ...,  0.9852, 10.4123, 32.8074],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "217\n",
      "torch.Size([4096]) tensor([53.3703, 27.0647,  6.2618,  ...,  0.9870, 10.4097, 32.8028],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "218\n",
      "torch.Size([4096]) tensor([53.3654, 27.0666,  6.2640,  ...,  0.9871, 10.4106, 32.7992],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "219\n",
      "torch.Size([4096]) tensor([53.3660, 27.0684,  6.2627,  ...,  0.9891, 10.4103, 32.7986],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "220\n",
      "torch.Size([4096]) tensor([53.3570, 27.0677,  6.2665,  ...,  0.9891, 10.4089, 32.7923],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "221\n",
      "torch.Size([4096]) tensor([53.3663, 27.0665,  6.2623,  ...,  0.9890, 10.4100, 32.7983],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "222\n",
      "torch.Size([4096]) tensor([53.3779, 27.0674,  6.2611,  ...,  0.9871, 10.4116, 32.8065],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "223\n",
      "torch.Size([4096]) tensor([53.3629, 27.0665,  6.2667,  ...,  0.9869, 10.4061, 32.7927],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "224\n",
      "torch.Size([4096]) tensor([53.3559, 27.0660,  6.2689,  ...,  0.9869, 10.4055, 32.7888],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "225\n",
      "torch.Size([4096]) tensor([53.3657, 27.0675,  6.2671,  ...,  0.9868, 10.4068, 32.7948],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "226\n",
      "torch.Size([4096]) tensor([53.3658, 27.0715,  6.2690,  ...,  0.9871, 10.4071, 32.7951],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "227\n",
      "torch.Size([4096]) tensor([53.3748, 27.0732,  6.2668,  ...,  0.9872, 10.4104, 32.8016],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "228\n",
      "torch.Size([4096]) tensor([53.3796, 27.0712,  6.2652,  ...,  0.9867, 10.4116, 32.8060],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "229\n",
      "torch.Size([4096]) tensor([53.3885, 27.0736,  6.2655,  ...,  0.9866, 10.4137, 32.8123],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "230\n",
      "torch.Size([4096]) tensor([53.3950, 27.0731,  6.2624,  ...,  0.9866, 10.4135, 32.8178],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "231\n",
      "torch.Size([4096]) tensor([53.4088, 27.0768,  6.2597,  ...,  0.9866, 10.4152, 32.8254],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "232\n",
      "torch.Size([4096]) tensor([53.3979, 27.0750,  6.2624,  ...,  0.9866, 10.4158, 32.8185],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "233\n",
      "torch.Size([4096]) tensor([53.4114, 27.0751,  6.2558,  ...,  0.9867, 10.4181, 32.8285],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "234\n",
      "torch.Size([4096]) tensor([53.3973, 27.0734,  6.2573,  ...,  0.9873, 10.4167, 32.8203],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "235\n",
      "torch.Size([4096]) tensor([53.3685, 27.0682,  6.2613,  ...,  0.9892, 10.4130, 32.8029],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "236\n",
      "torch.Size([4096]) tensor([53.3721, 27.0673,  6.2618,  ...,  0.9873, 10.4140, 32.8063],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "237\n",
      "torch.Size([4096]) tensor([53.3605, 27.0629,  6.2637,  ...,  0.9873, 10.4142, 32.8010],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "238\n",
      "torch.Size([4096]) tensor([53.3634, 27.0639,  6.2639,  ...,  0.9873, 10.4133, 32.7998],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "239\n",
      "torch.Size([4096]) tensor([53.3717, 27.0655,  6.2628,  ...,  0.9872, 10.4144, 32.8047],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.3608, 27.0640,  6.2653,  ...,  0.9885, 10.4120, 32.8011],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "241\n",
      "torch.Size([4096]) tensor([53.3656, 27.0624,  6.2618,  ...,  0.9889, 10.4173, 32.8078],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "242\n",
      "torch.Size([4096]) tensor([53.3566, 27.0625,  6.2624,  ...,  0.9910, 10.4165, 32.8029],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "243\n",
      "torch.Size([4096]) tensor([53.3454, 27.0625,  6.2662,  ...,  0.9896, 10.4147, 32.7950],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "244\n",
      "torch.Size([4096]) tensor([53.3594, 27.0651,  6.2630,  ...,  0.9892, 10.4162, 32.8036],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "245\n",
      "torch.Size([4096]) tensor([53.3582, 27.0642,  6.2608,  ...,  0.9914, 10.4172, 32.8036],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "246\n",
      "torch.Size([4096]) tensor([53.3557, 27.0633,  6.2591,  ...,  0.9916, 10.4157, 32.8008],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "247\n",
      "torch.Size([4096]) tensor([53.3694, 27.0650,  6.2575,  ...,  0.9897, 10.4163, 32.8101],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "248\n",
      "torch.Size([4096]) tensor([53.3689, 27.0644,  6.2588,  ...,  0.9895, 10.4155, 32.8077],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "249\n",
      "torch.Size([4096]) tensor([53.3745, 27.0649,  6.2580,  ...,  0.9895, 10.4154, 32.8091],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "250\n",
      "torch.Size([4096]) tensor([53.3758, 27.0638,  6.2570,  ...,  0.9895, 10.4159, 32.8109],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "251\n",
      "torch.Size([4096]) tensor([53.3726, 27.0611,  6.2572,  ...,  0.9890, 10.4152, 32.8098],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "252\n",
      "torch.Size([4096]) tensor([53.3787, 27.0612,  6.2558,  ...,  0.9888, 10.4155, 32.8131],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "253\n",
      "torch.Size([4096]) tensor([53.3763, 27.0632,  6.2565,  ...,  0.9893, 10.4152, 32.8109],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "254\n",
      "torch.Size([4096]) tensor([53.3749, 27.0631,  6.2595,  ...,  0.9885, 10.4156, 32.8114],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "255\n",
      "torch.Size([4096]) tensor([53.3860, 27.0642,  6.2550,  ...,  0.9904, 10.4165, 32.8202],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "256\n",
      "torch.Size([4096]) tensor([53.3868, 27.0653,  6.2551,  ...,  0.9904, 10.4166, 32.8204],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "257\n",
      "torch.Size([4096]) tensor([53.3866, 27.0651,  6.2563,  ...,  0.9885, 10.4165, 32.8207],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "258\n",
      "torch.Size([4096]) tensor([53.3851, 27.0647,  6.2560,  ...,  0.9884, 10.4162, 32.8204],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "259\n",
      "torch.Size([4096]) tensor([53.3749, 27.0638,  6.2600,  ...,  0.9865, 10.4138, 32.8124],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "260\n",
      "torch.Size([4096]) tensor([53.3682, 27.0616,  6.2599,  ...,  0.9883, 10.4138, 32.8068],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "261\n",
      "torch.Size([4096]) tensor([53.3649, 27.0591,  6.2592,  ...,  0.9882, 10.4133, 32.8041],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "262\n",
      "torch.Size([4096]) tensor([53.3665, 27.0623,  6.2609,  ...,  0.9883, 10.4119, 32.8012],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "263\n",
      "torch.Size([4096]) tensor([53.3771, 27.0644,  6.2585,  ...,  0.9868, 10.4127, 32.8075],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "264\n",
      "torch.Size([4096]) tensor([53.3767, 27.0637,  6.2577,  ...,  0.9883, 10.4135, 32.8083],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "265\n",
      "torch.Size([4096]) tensor([53.3770, 27.0656,  6.2570,  ...,  0.9888, 10.4140, 32.8092],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "266\n",
      "torch.Size([4096]) tensor([53.3951, 27.0692,  6.2545,  ...,  0.9871, 10.4166, 32.8216],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "267\n",
      "torch.Size([4096]) tensor([53.3904, 27.0684,  6.2558,  ...,  0.9871, 10.4159, 32.8177],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "268\n",
      "torch.Size([4096]) tensor([53.4025, 27.0683,  6.2514,  ...,  0.9889, 10.4179, 32.8254],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "269\n",
      "torch.Size([4096]) tensor([53.3993, 27.0687,  6.2524,  ...,  0.9890, 10.4180, 32.8249],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "270\n",
      "torch.Size([4096]) tensor([53.4027, 27.0700,  6.2565,  ...,  0.9866, 10.4179, 32.8270],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "271\n",
      "torch.Size([4096]) tensor([53.4115, 27.0697,  6.2520,  ...,  0.9871, 10.4197, 32.8336],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "272\n",
      "torch.Size([4096]) tensor([53.4277, 27.0702,  6.2461,  ...,  0.9873, 10.4203, 32.8439],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "273\n",
      "torch.Size([4096]) tensor([53.4339, 27.0706,  6.2497,  ...,  0.9846, 10.4216, 32.8499],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "274\n",
      "torch.Size([4096]) tensor([53.4280, 27.0689,  6.2481,  ...,  0.9852, 10.4215, 32.8474],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "275\n",
      "torch.Size([4096]) tensor([53.4389, 27.0693,  6.2457,  ...,  0.9851, 10.4226, 32.8531],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "276\n",
      "torch.Size([4096]) tensor([53.4310, 27.0683,  6.2472,  ...,  0.9852, 10.4220, 32.8492],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "277\n",
      "torch.Size([4096]) tensor([53.4158, 27.0634,  6.2472,  ...,  0.9871, 10.4206, 32.8412],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "278\n",
      "torch.Size([4096]) tensor([53.4188, 27.0621,  6.2454,  ...,  0.9871, 10.4251, 32.8452],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "279\n",
      "torch.Size([4096]) tensor([53.4097, 27.0591,  6.2450,  ...,  0.9889, 10.4237, 32.8398],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "280\n",
      "torch.Size([4096]) tensor([53.4128, 27.0567,  6.2456,  ...,  0.9856, 10.4225, 32.8418],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "281\n",
      "torch.Size([4096]) tensor([53.4105, 27.0603,  6.2491,  ...,  0.9852, 10.4213, 32.8392],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "282\n",
      "torch.Size([4096]) tensor([53.4043, 27.0584,  6.2507,  ...,  0.9851, 10.4201, 32.8350],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "283\n",
      "torch.Size([4096]) tensor([53.4222, 27.0611,  6.2487,  ...,  0.9836, 10.4217, 32.8438],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "284\n",
      "torch.Size([4096]) tensor([53.4245, 27.0660,  6.2495,  ...,  0.9851, 10.4198, 32.8447],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "285\n",
      "torch.Size([4096]) tensor([53.4290, 27.0650,  6.2476,  ...,  0.9851, 10.4208, 32.8491],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "286\n",
      "torch.Size([4096]) tensor([53.4329, 27.0674,  6.2485,  ...,  0.9850, 10.4204, 32.8489],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "287\n",
      "torch.Size([4096]) tensor([53.4431, 27.0679,  6.2463,  ...,  0.9846, 10.4240, 32.8579],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "288\n",
      "torch.Size([4096]) tensor([53.4335, 27.0672,  6.2482,  ...,  0.9845, 10.4245, 32.8531],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "289\n",
      "torch.Size([4096]) tensor([53.4307, 27.0664,  6.2485,  ...,  0.9845, 10.4239, 32.8502],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "290\n",
      "torch.Size([4096]) tensor([53.4305, 27.0654,  6.2482,  ...,  0.9844, 10.4200, 32.8485],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "291\n",
      "torch.Size([4096]) tensor([53.4072, 27.0620,  6.2531,  ...,  0.9844, 10.4182, 32.8333],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "292\n",
      "torch.Size([4096]) tensor([53.4135, 27.0627,  6.2507,  ...,  0.9845, 10.4205, 32.8370],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "293\n",
      "torch.Size([4096]) tensor([53.4176, 27.0629,  6.2496,  ...,  0.9845, 10.4210, 32.8432],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "294\n",
      "torch.Size([4096]) tensor([53.4128, 27.0609,  6.2502,  ...,  0.9845, 10.4220, 32.8400],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "295\n",
      "torch.Size([4096]) tensor([53.4292, 27.0653,  6.2456,  ...,  0.9864, 10.4244, 32.8504],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "296\n",
      "torch.Size([4096]) tensor([53.4321, 27.0627,  6.2451,  ...,  0.9850, 10.4241, 32.8524],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "297\n",
      "torch.Size([4096]) tensor([53.4234, 27.0647,  6.2473,  ...,  0.9866, 10.4237, 32.8486],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "298\n",
      "torch.Size([4096]) tensor([53.4203, 27.0636,  6.2497,  ...,  0.9847, 10.4233, 32.8466],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "299\n",
      "torch.Size([4096]) tensor([53.4195, 27.0592,  6.2432,  ...,  0.9882, 10.4239, 32.8475],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.3956, 27.0586,  6.2500,  ...,  0.9883, 10.4193, 32.8297],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "301\n",
      "torch.Size([4096]) tensor([53.3861, 27.0544,  6.2503,  ...,  0.9883, 10.4185, 32.8260],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "302\n",
      "torch.Size([4096]) tensor([53.3933, 27.0539,  6.2472,  ...,  0.9884, 10.4210, 32.8345],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "303\n",
      "torch.Size([4096]) tensor([53.3744, 27.0560,  6.2547,  ...,  0.9884, 10.4172, 32.8199],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "304\n",
      "torch.Size([4096]) tensor([53.3802, 27.0546,  6.2519,  ...,  0.9883, 10.4183, 32.8237],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "305\n",
      "torch.Size([4096]) tensor([53.3963, 27.0524,  6.2454,  ...,  0.9869, 10.4221, 32.8376],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "306\n",
      "torch.Size([4096]) tensor([53.3863, 27.0539,  6.2487,  ...,  0.9883, 10.4201, 32.8303],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "307\n",
      "torch.Size([4096]) tensor([53.3749, 27.0491,  6.2482,  ...,  0.9891, 10.4186, 32.8227],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "308\n",
      "torch.Size([4096]) tensor([53.3880, 27.0504,  6.2457,  ...,  0.9877, 10.4204, 32.8311],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "309\n",
      "torch.Size([4096]) tensor([53.3753, 27.0536,  6.2521,  ...,  0.9883, 10.4178, 32.8211],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "310\n",
      "torch.Size([4096]) tensor([53.3596, 27.0483,  6.2533,  ...,  0.9875, 10.4154, 32.8149],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "311\n",
      "torch.Size([4096]) tensor([53.3846, 27.0511,  6.2472,  ...,  0.9876, 10.4218, 32.8323],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "312\n",
      "torch.Size([4096]) tensor([53.3883, 27.0540,  6.2458,  ...,  0.9893, 10.4217, 32.8328],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "313\n",
      "torch.Size([4096]) tensor([53.3644, 27.0507,  6.2516,  ...,  0.9894, 10.4176, 32.8163],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "314\n",
      "torch.Size([4096]) tensor([53.3779, 27.0537,  6.2512,  ...,  0.9885, 10.4190, 32.8240],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "315\n",
      "torch.Size([4096]) tensor([53.4053, 27.0559,  6.2426,  ...,  0.9884, 10.4232, 32.8428],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "316\n",
      "torch.Size([4096]) tensor([53.4054, 27.0522,  6.2414,  ...,  0.9881, 10.4205, 32.8402],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "317\n",
      "torch.Size([4096]) tensor([53.4049, 27.0540,  6.2429,  ...,  0.9886, 10.4199, 32.8375],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "318\n",
      "torch.Size([4096]) tensor([53.4194, 27.0564,  6.2419,  ...,  0.9868, 10.4215, 32.8454],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "319\n",
      "torch.Size([4096]) tensor([53.4168, 27.0532,  6.2387,  ...,  0.9871, 10.4204, 32.8432],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "320\n",
      "torch.Size([4096]) tensor([53.4075, 27.0547,  6.2411,  ...,  0.9891, 10.4186, 32.8342],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "321\n",
      "torch.Size([4096]) tensor([53.4267, 27.0615,  6.2426,  ...,  0.9869, 10.4211, 32.8456],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "322\n",
      "torch.Size([4096]) tensor([53.4408, 27.0627,  6.2403,  ...,  0.9850, 10.4241, 32.8576],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "323\n",
      "torch.Size([4096]) tensor([53.4214, 27.0625,  6.2449,  ...,  0.9865, 10.4227, 32.8453],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "324\n",
      "torch.Size([4096]) tensor([53.4127, 27.0608,  6.2437,  ...,  0.9886, 10.4200, 32.8369],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "325\n",
      "torch.Size([4096]) tensor([53.4384, 27.0663,  6.2428,  ...,  0.9850, 10.4227, 32.8512],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "326\n",
      "torch.Size([4096]) tensor([53.4277, 27.0653,  6.2479,  ...,  0.9846, 10.4216, 32.8458],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "327\n",
      "torch.Size([4096]) tensor([53.4223, 27.0644,  6.2487,  ...,  0.9846, 10.4228, 32.8430],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "328\n",
      "torch.Size([4096]) tensor([53.4155, 27.0650,  6.2489,  ...,  0.9851, 10.4212, 32.8375],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "329\n",
      "torch.Size([4096]) tensor([53.4072, 27.0644,  6.2518,  ...,  0.9865, 10.4201, 32.8340],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "330\n",
      "torch.Size([4096]) tensor([53.4030, 27.0608,  6.2504,  ...,  0.9847, 10.4195, 32.8313],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "331\n",
      "torch.Size([4096]) tensor([53.4020, 27.0604,  6.2512,  ...,  0.9848, 10.4179, 32.8322],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "332\n",
      "torch.Size([4096]) tensor([53.4059, 27.0626,  6.2537,  ...,  0.9847, 10.4177, 32.8333],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "333\n",
      "torch.Size([4096]) tensor([53.4006, 27.0615,  6.2547,  ...,  0.9846, 10.4153, 32.8289],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "334\n",
      "torch.Size([4096]) tensor([53.4168, 27.0655,  6.2513,  ...,  0.9846, 10.4182, 32.8395],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "335\n",
      "torch.Size([4096]) tensor([53.4165, 27.0651,  6.2501,  ...,  0.9863, 10.4175, 32.8372],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "336\n",
      "torch.Size([4096]) tensor([53.4182, 27.0640,  6.2470,  ...,  0.9868, 10.4200, 32.8399],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "337\n",
      "torch.Size([4096]) tensor([53.4206, 27.0667,  6.2518,  ...,  0.9847, 10.4188, 32.8415],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "338\n",
      "torch.Size([4096]) tensor([53.4170, 27.0656,  6.2505,  ...,  0.9864, 10.4196, 32.8390],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "339\n",
      "torch.Size([4096]) tensor([53.4280, 27.0642,  6.2410,  ...,  0.9888, 10.4219, 32.8481],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "340\n",
      "torch.Size([4096]) tensor([53.4232, 27.0673,  6.2494,  ...,  0.9866, 10.4204, 32.8421],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "341\n",
      "torch.Size([4096]) tensor([53.4297, 27.0659,  6.2427,  ...,  0.9887, 10.4197, 32.8458],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "342\n",
      "torch.Size([4096]) tensor([53.4296, 27.0680,  6.2475,  ...,  0.9865, 10.4197, 32.8447],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "343\n",
      "torch.Size([4096]) tensor([53.4310, 27.0678,  6.2449,  ...,  0.9883, 10.4216, 32.8474],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "344\n",
      "torch.Size([4096]) tensor([53.4332, 27.0666,  6.2429,  ...,  0.9882, 10.4219, 32.8499],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "345\n",
      "torch.Size([4096]) tensor([53.4373, 27.0694,  6.2452,  ...,  0.9865, 10.4214, 32.8493],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "346\n",
      "torch.Size([4096]) tensor([53.4303, 27.0677,  6.2440,  ...,  0.9882, 10.4209, 32.8464],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "347\n",
      "torch.Size([4096]) tensor([53.4231, 27.0647,  6.2442,  ...,  0.9882, 10.4191, 32.8430],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "348\n",
      "torch.Size([4096]) tensor([53.4261, 27.0678,  6.2450,  ...,  0.9882, 10.4187, 32.8427],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "349\n",
      "torch.Size([4096]) tensor([53.4136, 27.0651,  6.2484,  ...,  0.9865, 10.4184, 32.8356],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "350\n",
      "torch.Size([4096]) tensor([53.3971, 27.0618,  6.2510,  ...,  0.9863, 10.4156, 32.8242],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "351\n",
      "torch.Size([4096]) tensor([53.4073, 27.0653,  6.2498,  ...,  0.9863, 10.4182, 32.8334],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "352\n",
      "torch.Size([4096]) tensor([53.4038, 27.0620,  6.2488,  ...,  0.9863, 10.4181, 32.8324],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "353\n",
      "torch.Size([4096]) tensor([53.4013, 27.0616,  6.2479,  ...,  0.9881, 10.4183, 32.8318],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "354\n",
      "torch.Size([4096]) tensor([53.4088, 27.0617,  6.2468,  ...,  0.9864, 10.4204, 32.8385],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "355\n",
      "torch.Size([4096]) tensor([53.3883, 27.0594,  6.2505,  ...,  0.9883, 10.4179, 32.8259],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "356\n",
      "torch.Size([4096]) tensor([53.3887, 27.0584,  6.2499,  ...,  0.9883, 10.4161, 32.8260],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "357\n",
      "torch.Size([4096]) tensor([53.3838, 27.0570,  6.2503,  ...,  0.9884, 10.4154, 32.8226],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "358\n",
      "torch.Size([4096]) tensor([53.3942, 27.0584,  6.2476,  ...,  0.9884, 10.4175, 32.8309],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "359\n",
      "torch.Size([4096]) tensor([53.3893, 27.0569,  6.2483,  ...,  0.9883, 10.4164, 32.8269],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.3836, 27.0583,  6.2510,  ...,  0.9883, 10.4148, 32.8209],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "361\n",
      "torch.Size([4096]) tensor([53.3952, 27.0610,  6.2488,  ...,  0.9884, 10.4162, 32.8278],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "362\n",
      "torch.Size([4096]) tensor([53.3938, 27.0596,  6.2480,  ...,  0.9883, 10.4163, 32.8270],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "363\n",
      "torch.Size([4096]) tensor([53.4058, 27.0606,  6.2464,  ...,  0.9869, 10.4175, 32.8337],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "364\n",
      "torch.Size([4096]) tensor([53.4006, 27.0616,  6.2465,  ...,  0.9883, 10.4165, 32.8303],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "365\n",
      "torch.Size([4096]) tensor([53.3929, 27.0618,  6.2490,  ...,  0.9884, 10.4152, 32.8250],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "366\n",
      "torch.Size([4096]) tensor([53.3968, 27.0607,  6.2481,  ...,  0.9882, 10.4162, 32.8294],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "367\n",
      "torch.Size([4096]) tensor([53.3980, 27.0596,  6.2482,  ...,  0.9863, 10.4166, 32.8311],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "368\n",
      "torch.Size([4096]) tensor([53.4045, 27.0620,  6.2461,  ...,  0.9882, 10.4180, 32.8336],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "369\n",
      "torch.Size([4096]) tensor([53.4074, 27.0629,  6.2460,  ...,  0.9863, 10.4193, 32.8366],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "370\n",
      "torch.Size([4096]) tensor([53.4065, 27.0668,  6.2491,  ...,  0.9863, 10.4171, 32.8324],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "371\n",
      "torch.Size([4096]) tensor([53.3977, 27.0678,  6.2529,  ...,  0.9863, 10.4160, 32.8272],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "372\n",
      "torch.Size([4096]) tensor([53.4063, 27.0692,  6.2528,  ...,  0.9844, 10.4174, 32.8335],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "373\n",
      "torch.Size([4096]) tensor([53.4028, 27.0725,  6.2567,  ...,  0.9844, 10.4151, 32.8275],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "374\n",
      "torch.Size([4096]) tensor([53.3982, 27.0727,  6.2580,  ...,  0.9845, 10.4156, 32.8264],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "375\n",
      "torch.Size([4096]) tensor([53.4231, 27.0763,  6.2511,  ...,  0.9845, 10.4198, 32.8433],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "376\n",
      "torch.Size([4096]) tensor([53.4224, 27.0770,  6.2514,  ...,  0.9846, 10.4197, 32.8410],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "377\n",
      "torch.Size([4096]) tensor([53.4140, 27.0774,  6.2544,  ...,  0.9848, 10.4192, 32.8358],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "378\n",
      "torch.Size([4096]) tensor([53.4296, 27.0797,  6.2501,  ...,  0.9865, 10.4211, 32.8422],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "379\n",
      "torch.Size([4096]) tensor([53.4262, 27.0814,  6.2532,  ...,  0.9846, 10.4189, 32.8395],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "380\n",
      "torch.Size([4096]) tensor([53.4310, 27.0821,  6.2516,  ...,  0.9846, 10.4203, 32.8441],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "381\n",
      "torch.Size([4096]) tensor([53.4352, 27.0814,  6.2484,  ...,  0.9865, 10.4216, 32.8474],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "382\n",
      "torch.Size([4096]) tensor([53.4124, 27.0773,  6.2542,  ...,  0.9846, 10.4191, 32.8332],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "383\n",
      "torch.Size([4096]) tensor([53.4233, 27.0799,  6.2506,  ...,  0.9867, 10.4215, 32.8419],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "384\n",
      "torch.Size([4096]) tensor([53.4262, 27.0801,  6.2496,  ...,  0.9867, 10.4208, 32.8429],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "385\n",
      "torch.Size([4096]) tensor([53.4039, 27.0762,  6.2535,  ...,  0.9869, 10.4181, 32.8280],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "386\n",
      "torch.Size([4096]) tensor([53.4101, 27.0759,  6.2513,  ...,  0.9869, 10.4212, 32.8348],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "387\n",
      "torch.Size([4096]) tensor([53.4120, 27.0761,  6.2492,  ...,  0.9889, 10.4232, 32.8370],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "388\n",
      "torch.Size([4096]) tensor([53.4189, 27.0771,  6.2490,  ...,  0.9870, 10.4227, 32.8415],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "389\n",
      "torch.Size([4096]) tensor([53.4149, 27.0740,  6.2491,  ...,  0.9869, 10.4229, 32.8394],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "390\n",
      "torch.Size([4096]) tensor([53.4147, 27.0755,  6.2491,  ...,  0.9870, 10.4208, 32.8387],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "391\n",
      "torch.Size([4096]) tensor([53.4236, 27.0759,  6.2462,  ...,  0.9870, 10.4222, 32.8446],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "392\n",
      "torch.Size([4096]) tensor([53.4168, 27.0776,  6.2480,  ...,  0.9890, 10.4215, 32.8390],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "393\n",
      "torch.Size([4096]) tensor([53.4194, 27.0783,  6.2497,  ...,  0.9869, 10.4213, 32.8403],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "394\n",
      "torch.Size([4096]) tensor([53.4165, 27.0751,  6.2498,  ...,  0.9865, 10.4211, 32.8400],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "395\n",
      "torch.Size([4096]) tensor([53.4170, 27.0783,  6.2509,  ...,  0.9869, 10.4212, 32.8380],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "396\n",
      "torch.Size([4096]) tensor([53.4333, 27.0794,  6.2463,  ...,  0.9869, 10.4224, 32.8470],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "397\n",
      "torch.Size([4096]) tensor([53.4149, 27.0734,  6.2499,  ...,  0.9864, 10.4197, 32.8353],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "398\n",
      "torch.Size([4096]) tensor([53.4177, 27.0737,  6.2499,  ...,  0.9864, 10.4197, 32.8362],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "399\n",
      "torch.Size([4096]) tensor([53.4084, 27.0723,  6.2530,  ...,  0.9845, 10.4166, 32.8261],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "400\n",
      "torch.Size([4096]) tensor([53.4232, 27.0737,  6.2449,  ...,  0.9885, 10.4191, 32.8378],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "401\n",
      "torch.Size([4096]) tensor([53.4284, 27.0752,  6.2457,  ...,  0.9867, 10.4202, 32.8422],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "402\n",
      "torch.Size([4096]) tensor([53.4281, 27.0747,  6.2454,  ...,  0.9863, 10.4198, 32.8411],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "403\n",
      "torch.Size([4096]) tensor([53.4388, 27.0764,  6.2446,  ...,  0.9844, 10.4208, 32.8481],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "404\n",
      "torch.Size([4096]) tensor([53.4229, 27.0741,  6.2487,  ...,  0.9844, 10.4182, 32.8374],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "405\n",
      "torch.Size([4096]) tensor([53.4343, 27.0738,  6.2446,  ...,  0.9844, 10.4214, 32.8465],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "406\n",
      "torch.Size([4096]) tensor([53.4385, 27.0762,  6.2453,  ...,  0.9845, 10.4219, 32.8490],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "407\n",
      "torch.Size([4096]) tensor([53.4355, 27.0760,  6.2460,  ...,  0.9844, 10.4206, 32.8452],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "408\n",
      "torch.Size([4096]) tensor([53.4426, 27.0747,  6.2407,  ...,  0.9864, 10.4224, 32.8531],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "409\n",
      "torch.Size([4096]) tensor([53.4330, 27.0748,  6.2444,  ...,  0.9845, 10.4216, 32.8478],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "410\n",
      "torch.Size([4096]) tensor([53.4396, 27.0744,  6.2412,  ...,  0.9844, 10.4227, 32.8524],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "411\n",
      "torch.Size([4096]) tensor([53.4474, 27.0772,  6.2391,  ...,  0.9864, 10.4235, 32.8567],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "412\n",
      "torch.Size([4096]) tensor([53.4412, 27.0729,  6.2373,  ...,  0.9867, 10.4228, 32.8540],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "413\n",
      "torch.Size([4096]) tensor([53.4337, 27.0687,  6.2384,  ...,  0.9852, 10.4212, 32.8483],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "414\n",
      "torch.Size([4096]) tensor([53.4211, 27.0684,  6.2421,  ...,  0.9870, 10.4176, 32.8356],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "415\n",
      "torch.Size([4096]) tensor([53.4237, 27.0716,  6.2417,  ...,  0.9870, 10.4174, 32.8358],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "416\n",
      "torch.Size([4096]) tensor([53.4174, 27.0723,  6.2445,  ...,  0.9864, 10.4139, 32.8304],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "417\n",
      "torch.Size([4096]) tensor([53.4115, 27.0723,  6.2457,  ...,  0.9851, 10.4122, 32.8253],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "418\n",
      "torch.Size([4096]) tensor([53.4226, 27.0745,  6.2441,  ...,  0.9851, 10.4152, 32.8356],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "419\n",
      "torch.Size([4096]) tensor([53.4259, 27.0773,  6.2460,  ...,  0.9833, 10.4150, 32.8362],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.4381, 27.0760,  6.2403,  ...,  0.9852, 10.4176, 32.8457],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "421\n",
      "torch.Size([4096]) tensor([53.4304, 27.0758,  6.2436,  ...,  0.9853, 10.4159, 32.8401],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "422\n",
      "torch.Size([4096]) tensor([53.4447, 27.0795,  6.2423,  ...,  0.9852, 10.4180, 32.8495],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "423\n",
      "torch.Size([4096]) tensor([53.4579, 27.0804,  6.2380,  ...,  0.9852, 10.4218, 32.8579],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "424\n",
      "torch.Size([4096]) tensor([53.4403, 27.0775,  6.2427,  ...,  0.9851, 10.4215, 32.8453],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "425\n",
      "torch.Size([4096]) tensor([53.4420, 27.0762,  6.2394,  ...,  0.9869, 10.4199, 32.8481],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "426\n",
      "torch.Size([4096]) tensor([53.4400, 27.0746,  6.2400,  ...,  0.9852, 10.4214, 32.8495],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "427\n",
      "torch.Size([4096]) tensor([53.4397, 27.0776,  6.2412,  ...,  0.9853, 10.4201, 32.8458],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "428\n",
      "torch.Size([4096]) tensor([53.4310, 27.0766,  6.2421,  ...,  0.9871, 10.4176, 32.8375],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "429\n",
      "torch.Size([4096]) tensor([53.4362, 27.0766,  6.2398,  ...,  0.9871, 10.4188, 32.8427],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "430\n",
      "torch.Size([4096]) tensor([53.4400, 27.0790,  6.2404,  ...,  0.9870, 10.4188, 32.8442],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "431\n",
      "torch.Size([4096]) tensor([53.4477, 27.0798,  6.2373,  ...,  0.9871, 10.4202, 32.8500],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "432\n",
      "torch.Size([4096]) tensor([53.4587, 27.0797,  6.2323,  ...,  0.9872, 10.4218, 32.8563],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "433\n",
      "torch.Size([4096]) tensor([53.4656, 27.0804,  6.2347,  ...,  0.9833, 10.4234, 32.8630],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "434\n",
      "torch.Size([4096]) tensor([53.4563, 27.0800,  6.2355,  ...,  0.9872, 10.4206, 32.8575],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "435\n",
      "torch.Size([4096]) tensor([53.4604, 27.0784,  6.2350,  ...,  0.9856, 10.4210, 32.8600],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "436\n",
      "torch.Size([4096]) tensor([53.4513, 27.0764,  6.2349,  ...,  0.9859, 10.4202, 32.8547],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "437\n",
      "torch.Size([4096]) tensor([53.4451, 27.0766,  6.2381,  ...,  0.9853, 10.4200, 32.8528],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "438\n",
      "torch.Size([4096]) tensor([53.4291, 27.0749,  6.2426,  ...,  0.9854, 10.4171, 32.8426],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "439\n",
      "torch.Size([4096]) tensor([53.4289, 27.0741,  6.2417,  ...,  0.9853, 10.4186, 32.8405],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "440\n",
      "torch.Size([4096]) tensor([53.4364, 27.0741,  6.2402,  ...,  0.9852, 10.4193, 32.8455],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "441\n",
      "torch.Size([4096]) tensor([53.4451, 27.0755,  6.2397,  ...,  0.9834, 10.4190, 32.8483],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "442\n",
      "torch.Size([4096]) tensor([53.4548, 27.0754,  6.2360,  ...,  0.9834, 10.4216, 32.8563],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "443\n",
      "torch.Size([4096]) tensor([53.4510, 27.0786,  6.2391,  ...,  0.9852, 10.4204, 32.8531],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "444\n",
      "torch.Size([4096]) tensor([53.4667, 27.0809,  6.2376,  ...,  0.9815, 10.4226, 32.8641],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "445\n",
      "torch.Size([4096]) tensor([53.4605, 27.0802,  6.2383,  ...,  0.9835, 10.4221, 32.8607],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "446\n",
      "torch.Size([4096]) tensor([53.4663, 27.0822,  6.2381,  ...,  0.9850, 10.4236, 32.8656],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "447\n",
      "torch.Size([4096]) tensor([53.4518, 27.0794,  6.2403,  ...,  0.9853, 10.4215, 32.8558],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "448\n",
      "torch.Size([4096]) tensor([53.4417, 27.0760,  6.2436,  ...,  0.9833, 10.4211, 32.8477],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "449\n",
      "torch.Size([4096]) tensor([53.4298, 27.0771,  6.2453,  ...,  0.9866, 10.4199, 32.8404],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "450\n",
      "torch.Size([4096]) tensor([53.4150, 27.0719,  6.2489,  ...,  0.9843, 10.4156, 32.8320],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "451\n",
      "torch.Size([4096]) tensor([53.4246, 27.0713,  6.2460,  ...,  0.9846, 10.4160, 32.8360],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "452\n",
      "torch.Size([4096]) tensor([53.4287, 27.0746,  6.2447,  ...,  0.9845, 10.4159, 32.8364],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "453\n",
      "torch.Size([4096]) tensor([53.4412, 27.0731,  6.2427,  ...,  0.9827, 10.4184, 32.8461],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "454\n",
      "torch.Size([4096]) tensor([53.4289, 27.0710,  6.2435,  ...,  0.9841, 10.4173, 32.8397],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "455\n",
      "torch.Size([4096]) tensor([53.4433, 27.0758,  6.2411,  ...,  0.9842, 10.4192, 32.8498],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "456\n",
      "torch.Size([4096]) tensor([53.4593, 27.0781,  6.2390,  ...,  0.9827, 10.4216, 32.8606],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "457\n",
      "torch.Size([4096]) tensor([53.4490, 27.0774,  6.2422,  ...,  0.9826, 10.4189, 32.8510],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "458\n",
      "torch.Size([4096]) tensor([53.4507, 27.0790,  6.2422,  ...,  0.9827, 10.4191, 32.8525],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "459\n",
      "torch.Size([4096]) tensor([53.4389, 27.0772,  6.2433,  ...,  0.9841, 10.4160, 32.8459],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "460\n",
      "torch.Size([4096]) tensor([53.4299, 27.0782,  6.2476,  ...,  0.9841, 10.4141, 32.8379],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "461\n",
      "torch.Size([4096]) tensor([53.4231, 27.0775,  6.2494,  ...,  0.9841, 10.4127, 32.8334],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "462\n",
      "torch.Size([4096]) tensor([53.4377, 27.0807,  6.2471,  ...,  0.9839, 10.4137, 32.8412],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "463\n",
      "torch.Size([4096]) tensor([53.4389, 27.0845,  6.2484,  ...,  0.9840, 10.4134, 32.8405],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "464\n",
      "torch.Size([4096]) tensor([53.4456, 27.0847,  6.2465,  ...,  0.9839, 10.4161, 32.8441],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "465\n",
      "torch.Size([4096]) tensor([53.4452, 27.0844,  6.2449,  ...,  0.9841, 10.4158, 32.8485],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "466\n",
      "torch.Size([4096]) tensor([53.4418, 27.0858,  6.2484,  ...,  0.9841, 10.4149, 32.8457],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "467\n",
      "torch.Size([4096]) tensor([53.4316, 27.0845,  6.2513,  ...,  0.9840, 10.4122, 32.8355],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "468\n",
      "torch.Size([4096]) tensor([53.4478, 27.0852,  6.2476,  ...,  0.9839, 10.4145, 32.8464],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "469\n",
      "torch.Size([4096]) tensor([53.4348, 27.0839,  6.2507,  ...,  0.9841, 10.4128, 32.8376],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "470\n",
      "torch.Size([4096]) tensor([53.4353, 27.0834,  6.2503,  ...,  0.9841, 10.4144, 32.8369],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "471\n",
      "torch.Size([4096]) tensor([53.4523, 27.0845,  6.2455,  ...,  0.9840, 10.4180, 32.8499],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "472\n",
      "torch.Size([4096]) tensor([53.4590, 27.0930,  6.2498,  ...,  0.9841, 10.4181, 32.8506],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "473\n",
      "torch.Size([4096]) tensor([53.4454, 27.0943,  6.2538,  ...,  0.9843, 10.4159, 32.8411],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "474\n",
      "torch.Size([4096]) tensor([53.4478, 27.0915,  6.2511,  ...,  0.9841, 10.4162, 32.8445],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "475\n",
      "torch.Size([4096]) tensor([53.4436, 27.0926,  6.2535,  ...,  0.9841, 10.4152, 32.8408],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "476\n",
      "torch.Size([4096]) tensor([53.4399, 27.0953,  6.2547,  ...,  0.9859, 10.4120, 32.8362],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "477\n",
      "torch.Size([4096]) tensor([53.4548, 27.0976,  6.2527,  ...,  0.9841, 10.4143, 32.8448],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "478\n",
      "torch.Size([4096]) tensor([53.4449, 27.0972,  6.2542,  ...,  0.9858, 10.4125, 32.8388],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "479\n",
      "torch.Size([4096]) tensor([53.4498, 27.0958,  6.2518,  ...,  0.9858, 10.4152, 32.8417],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096]) tensor([53.4474, 27.0966,  6.2524,  ...,  0.9859, 10.4155, 32.8400],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "481\n",
      "torch.Size([4096]) tensor([53.4632, 27.0997,  6.2508,  ...,  0.9850, 10.4181, 32.8484],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "482\n",
      "torch.Size([4096]) tensor([53.4844, 27.0993,  6.2446,  ...,  0.9848, 10.4207, 32.8635],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "483\n",
      "torch.Size([4096]) tensor([53.4938, 27.0994,  6.2435,  ...,  0.9829, 10.4221, 32.8688],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "484\n",
      "torch.Size([4096]) tensor([53.4891, 27.1016,  6.2455,  ...,  0.9830, 10.4213, 32.8652],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "485\n",
      "torch.Size([4096]) tensor([53.5078, 27.1050,  6.2387,  ...,  0.9867, 10.4223, 32.8785],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "486\n",
      "torch.Size([4096]) tensor([53.4909, 27.1048,  6.2457,  ...,  0.9849, 10.4196, 32.8658],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "487\n",
      "torch.Size([4096]) tensor([53.4981, 27.1097,  6.2463,  ...,  0.9850, 10.4199, 32.8684],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "488\n",
      "torch.Size([4096]) tensor([53.5042, 27.1092,  6.2399,  ...,  0.9904, 10.4196, 32.8719],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "489\n",
      "torch.Size([4096]) tensor([53.4795, 27.1041,  6.2510,  ...,  0.9847, 10.4145, 32.8529],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "490\n",
      "torch.Size([4096]) tensor([53.4932, 27.1036,  6.2447,  ...,  0.9865, 10.4173, 32.8638],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "491\n",
      "torch.Size([4096]) tensor([53.4995, 27.1059,  6.2446,  ...,  0.9850, 10.4196, 32.8699],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "492\n",
      "torch.Size([4096]) tensor([53.4917, 27.1052,  6.2463,  ...,  0.9850, 10.4203, 32.8642],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "493\n",
      "torch.Size([4096]) tensor([53.4994, 27.1050,  6.2437,  ...,  0.9848, 10.4192, 32.8694],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "494\n",
      "torch.Size([4096]) tensor([53.4914, 27.1086,  6.2486,  ...,  0.9850, 10.4185, 32.8641],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "495\n",
      "torch.Size([4096]) tensor([53.5056, 27.1100,  6.2415,  ...,  0.9886, 10.4237, 32.8763],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "496\n",
      "torch.Size([4096]) tensor([53.4948, 27.1055,  6.2460,  ...,  0.9849, 10.4198, 32.8697],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "497\n",
      "torch.Size([4096]) tensor([53.4676, 27.1026,  6.2510,  ...,  0.9868, 10.4184, 32.8525],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "498\n",
      "torch.Size([4096]) tensor([53.4789, 27.1045,  6.2494,  ...,  0.9851, 10.4210, 32.8615],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "499\n",
      "torch.Size([4096]) tensor([53.4612, 27.1055,  6.2558,  ...,  0.9853, 10.4165, 32.8483],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "torch.Size([500, 4096]) torch.Size([500, 4096])\n",
      "tensor(6.0528, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "6.052822589874268\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-36ae6c3d7b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtotalLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0madOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "for epoch in range(Epochs):\n",
    "    print(epoch)\n",
    "    np.random.shuffle(perm)\n",
    "    i = 0\n",
    "    totalLoss = 0.0\n",
    "    for eachVal in perm:\n",
    "        if(eachVal == 31):\n",
    "            continue\n",
    "        print(i,eachVal)\n",
    "        adOptimizer.zero_grad()\n",
    "        sample = torch.from_numpy(np.load('ProteinData/ProteinData' + str(eachVal)+ '.npy')[0] ).type('torch.FloatTensor').to('cuda')\n",
    "        mdObj = torch.from_numpy(xtObject.xyz[eachVal*500:(eachVal+1)*500,:42].reshape(500,42*3)).type('torch.FloatTensor')\n",
    "        print(sample.sum()/500)\n",
    "        out = configModel(mdObj.to('cuda'))\n",
    "        print(out.shape)\n",
    "        loss = DensitylossFunction(out,sample)\n",
    "        print(loss)\n",
    "        #loss = (torch.abs(out-sample)/sample).mean()\n",
    "        \n",
    "        mdObj = None\n",
    "        sample = None\n",
    "        out = None\n",
    "        print(loss.item())\n",
    "        totalLoss += loss.item()\n",
    "        i+=1\n",
    "        loss.backward()\n",
    "        adOptimizer.step( )\n",
    "    print(totalLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
